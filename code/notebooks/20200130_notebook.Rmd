---
title: "Racist hypothesis notebook"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

# Source packages and functions

```{r}
library(here)
source(here::here("code", "scripts", "20200318_notebook_source.R"))
```

*20200130*

# Data

• 1KG final release VCFs: <ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/>
• Educational attainment paper: <https://www.nature.com/articles/s41588-018-0147-3>
• Lead loci from that paper: `racist_hypothesis/data/20200130_iq_gwas_topf.csv`

Papers:

• Berg J. J., Coop G., 2014 'A population genetic signal of polygenic adaptation'. PLoS Genetics 10: e1004412 
• Also their 2017 paper <https://www.biorxiv.org/content/10.1101/167551v4>
• Spiedel et al on a tool for inferring genealogy (and hence changes in allele frequencies, hence selection): <https://www.nature.com/articles/s41588-019-0484-x>

# Cluster structure

Home: `/hps/research1/birney/users/ian/rac_hyp`

```{bash}
mkcd vcfs

# download VCF and index
wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.wgs.phase3_shapeit2_mvncall_integrated_v5b.20130502.sites.vcf.gz
wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.wgs.phase3_shapeit2_mvncall_integrated_v5b.20130502.sites.vcf.gz.tbi
```

## Update GATK

```{bash}
cd /nfs/software/birney
wget https://github.com/broadinstitute/gatk/releases/download/4.1.4.1/gatk-4.1.4.1.zip
unzip gatk-4.1.4.1.zip

# amend aliases in ~/.bashrc and ~/.bash_profile
export PATH=$PATH:/nfs/software/birney/gatk-4.1.4.1/
```

## Set up reference
```{bash}
mkcd refs
# download FASTA
wget ftp://ftp.ensembl.org/pub/release-99/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.toplevel.fa.gz
# create dictionary follwoing guiadance here: <https://gatkforums.broadinstitute.org/gatk/discussion/1601/how-can-i-prepare-a-fasta-file-to-use-as-reference>
java -jar /nfs/software/birney/picard-2.9.0/picard.jar CreateSequenceDictionary \
  R=refs/Homo_sapiens.GRCh38.dna.toplevel.fa.gz \
  O=refs/Homo_sapiens.GRCh38.dna.toplevel.dict
# create fasta index file
/nfs/software/birney/samtools-1.9/samtools faidx refs/Homo_sapiens.GRCh38.dna.toplevel.fa.gz
# [E::fai_build3_core] Cannot index files compressed with gzip, please use bgzip
## unzip 
gunzip refs/Homo_sapiens.GRCh38.dna.toplevel.fa.gz
## create dictionary again
rm refs/Homo_sapiens.GRCh38.dna.toplevel.dict
java -jar /nfs/software/birney/picard-2.9.0/picard.jar CreateSequenceDictionary \
  R=refs/Homo_sapiens.GRCh38.dna.toplevel.fa \
  O=refs/Homo_sapiens.GRCh38.dna.toplevel.dict
# create gast index file
/nfs/software/birney/samtools-1.9/samtools faidx refs/Homo_sapiens.GRCh38.dna.toplevel.fa
```

## Create list of SNPs from top hits table: `racist_hypothesis/data/20200204_snps.list`
```{bash}
cut racist_hypothesis/data/20200204_iq_gwas_topf -f5 -d"," | sed 's/"//g' | tail -n+2 > racist_hypothesis/data/20200204_snps.list 
```

# Pull out SNPs from VCF based on loci

```{bash}
gatk SelectVariants \
  -R refs/Homo_sapiens.GRCh38.dna.toplevel.fa \
  -V vcfs/ALL.wgs.phase3_shapeit2_mvncall_integrated_v5b.20130502.sites.vcf.gz \
  --keep-ids racist_hypothesis/data/20200204_snps.list \
  -O vcfs/ALL.hits.vcf.gz
# Error initializing feature reader for path vcfs/ALL.wgs.phase3_shapeit2_mvncall_integrated_v5b.20130502.sites.vcf.gz
# Caused by: htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to parse header with error: Invalid GZIP header, for input source: vcfs/ALL.wgs.phase3_shapeit2_mvncall_integrated_v5b.20130502.sites.vcf.gz  
```

This VCF doesn't have the per-sample calls, but just the allele frequencies for each continental population.

Have to download all the VCFs on the page, then put them together.

## Download

```{bash}
wget -r -p -k --no-parent -cut-dirs=5 ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/
```

## Put list of files into list

```{bash}
find vcfs/ftp.1000genomes.ebi.ac.uk/ALL.chr*.vcf.gz > racist_hypothesis/data/20200205_vcfs.list
```

## Merge VCFs

```{bash}
java -jar /nfs/software/birney/picard-2.9.0/picard.jar MergeVcfs \
  I=racist_hypothesis/data/20200205_vcfs.list \
  O=vcfs/1gk_all.vcf.gz
# Exception in thread "main" java.lang.IllegalArgumentException: The contig entries in input file /hps/research1/birney/users/ian/rac_hyp/vcfs/ftp.1000genomes.ebi.ac.uk/ALL.chrMT.phase3_callmom-v0_4.20130502.genotypes.vcf.gz are not compatible with the others.

# So remove that one from list above
sed -i '/MT/d' racist_hypothesis/data/20200205_vcfs.list

# run MergeVCFs again
java -jar /nfs/software/birney/picard-2.9.0/picard.jar MergeVcfs \
  I=racist_hypothesis/data/20200205_vcfs.list \
  O=vcfs/1gk_all.vcf.gz
  
# Exception in thread "main" java.lang.IllegalArgumentException: The contig entries in input file /hps/research1/birney/users/ian/rac_hyp/vcfs/ftp.1000genomes.ebi.ac.uk/ALL.chrY.phase3_integrated_v2a.20130502.genotypes.vcf.gz are not compatible with the others.
sed -i '/chrY/d' racist_hypothesis/data/20200205_vcfs.list

# run MergeVCFs again
java -jar /nfs/software/birney/picard-2.9.0/picard.jar MergeVcfs \
  I=racist_hypothesis/data/20200205_vcfs.list \
  O=vcfs/1gk_all.vcf.gz
# WORKS
```

## Get reference used for this callset
```{bash}
# Find out which reference is used by the callset
bcftools view vcfs/1gk_all.vcf.gz | less
# ftp://ftp.1000genomes.ebi.ac.uk//vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz

# download that reference
cd refs
wget ftp://ftp.1000genomes.ebi.ac.uk//vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz
# create index
/nfs/software/birney/samtools-1.9/samtools faidx refs/hs37d5.fa.gz
# create dictionary
java -jar /nfs/software/birney/picard-2.9.0/picard.jar CreateSequenceDictionary \
  R=refs/hs37d5.fa.gz \
  O=refs/hs37d5.dict
```

## Pull out SNPs

```{bash}
gatk SelectVariants \
  -R refs/hs37d5.fa.gz \
  -V vcfs/1gk_all.vcf.gz \
  --keep-ids racist_hypothesis/data/20200204_snps.list \
  -O vcfs/snp_hits.vcf.gz
# SUCCESS
```

## Copy to repo

```{bash}
cp vcfs/snp_hits.vcf.gz racist_hypothesis/data/20200303_snp_hits.vcf.gz
cp vcfs/snp_hits.vcf.gz.tbi racist_hypothesis/data/20200303_snp_hits.vcf.gz.tbi
```

## Import into R

```{r}
snp_hits <- pegas::read.vcf(here::here("data", "20200303_snp_hits.vcf.gz"))
```

## Import sample info

From here: <http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/working/20130606_sample_info/20130606_sample_info.xlsx> (link embedded in this page: <www.internationalgenome.org/data>)

```{r}
meta <- read_xlsx(here::here("data", "20130606_sample_info.xlsx"), sheet = "Sample Info") %>% dplyr::select(Sample, Population, Gender)
```

## Attach population column to snp_hits

```{r}
populations <- unlist(lapply(rownames(snp_hits), function(sample){
  meta$Population[meta$Sample == sample]
}))
snp_hits$population <- populations
# reorder
snp_hits <- snp_hits %>% dplyr::select(population, everything())
# split by population
snp_hits_split <- split(snp_hits, f = snp_hits$population)
# remove population columns
snp_hits_split <- lapply(snp_hits_split, function(x){
  x$population <- NULL
  return(x)
})

# get allele counts
allele_counts <- lapply(snp_hits_split, function(population){
  summary(population)
})
```

## Import list of SNPs with alleles

```{r}
snp_al_nos <- read.delim("~/Documents/Repositories/racist_hypothesis/data/20200303_top_snps_with_alleles.txt", as.is = T)
```

## Create data frames with allele frequences

```{r}
# TEST
test <- allele_counts[["ACB"]][["rs79582714"]]
test2 <- data.frame("allele" = names(test$allele),
                    "count" = test$allele)
test2$al_freq <- test2$count / sum(test2$count)
z_scores <- data.frame("allele" = c(snp_al_nos$Allele1[snp_al_nos$SNP == "rs79582714"],
                                    snp_al_nos$Allele2[snp_al_nos$SNP == "rs79582714"]),
                       "z_score" = c(0, snp_al_nos$Z.Score[snp_al_nos$SNP == "rs79582714"]))
test3 <- dplyr::left_join(test2, z_scores, by = "allele")

# Create function
get_alfreq_table <- function(population, snp_effects_df){
  counter <- 0
  population <- lapply(population, function(snp_summary){
    # set counter and extract SNP ID
    counter <<- counter + 1
    snp_id <- names(population)[counter]
    # create final DF
    final_df <- data.frame("allele" = names(snp_summary$allele),
                           "count" = snp_summary$allele,
                           stringsAsFactors = F)
    # get allele frequency
    final_df$al_freq <- final_df$count / sum(final_df$count)
    # pull out z-scores and p-values from snp_effects_df
    z_scores <- data.frame("allele" = c(snp_effects_df$Allele1[snp_effects_df$SNP == snp_id],
                                        snp_effects_df$Allele2[snp_effects_df$SNP == snp_id]),
                           "z_score" = c(0, snp_effects_df$Z.Score[snp_effects_df$SNP == snp_id]),
                           "p_value" = c(0, snp_effects_df$P[snp_effects_df$SNP == snp_id]),
                           stringsAsFactors = F)
    # join DFs. Note that it only joins the two alleles in the snp_effects_df
    final_df <- dplyr::left_join(z_scores, final_df, by = "allele")
    return(final_df)
  })
  return(population)
}

# Run over list
alcnt_df_lst <- lapply(allele_counts, function(x){
  out <- get_alfreq_table(x, snp_al_nos)
  final <- dplyr::bind_rows(out, .id = "rsid")
  return(final)
})

# create final DF
alcnt_df <- dplyr::bind_rows(alcnt_df_lst, .id = "population")

# filter only for alleles with an efffect
alcnt_df_filt <- alcnt_df[alcnt_df$z_score != 0, ]

# set new rownames
rownames(alcnt_df_filt) <- seq(1:nrow(alcnt_df_filt))
```

# Plot

## Separate columns to plot on either axis

```{r}
# filter for just al_freq
plot_df <- alcnt_df_filt %>% dplyr::select(-count, )
plot_df <- tidyr::pivot_wider(data = plot_df,
                              names_from = population,
                              names_prefix = "al_freq_",
                              values_from = al_freq)

dplyr::filter(plot_df, z_score <= 0)
```

## Plot

### YRI v CEU

```{r}
ggplot(data = dplyr::filter(plot_df, z_score <= 0), aes(al_freq_YRI, al_freq_CEU, colour = z_score)) +
  geom_point() +
  scale_color_viridis_c() +
  coord_fixed() +
  geom_smooth(se = F) +
  geom_abline(intercept = 0, slope = 1) +
  ggtitle("IQ-negative alleles")

ggplot(data = dplyr::filter(plot_df, z_score >= 0), aes(al_freq_YRI, al_freq_CEU, colour = z_score)) +
  geom_point() +
  scale_color_viridis_c() +
  coord_fixed() +
  geom_smooth(se = F) +
  geom_abline(intercept = 0, slope = 1) +
  ggtitle("IQ-positive alleles")
```

### YRI v CHS

```{r}
ggplot(data = dplyr::filter(plot_df, z_score <= 0), aes(al_freq_YRI, al_freq_CHS, colour = z_score)) +
  geom_point() +
  scale_color_viridis_c() +
  coord_fixed() +
  geom_smooth(se = F) +
  geom_abline(intercept = 0, slope = 1) +
  ggtitle("IQ-negative alleles")

ggplot(data = dplyr::filter(plot_df, z_score >= 0), aes(al_freq_YRI, al_freq_CHS, colour = z_score)) +
  geom_point() +
  scale_color_viridis_c() +
  coord_fixed() +
  geom_smooth(se = F) +
  geom_abline(intercept = 0, slope = 1) +
  ggtitle("IQ-positive alleles")
```

### CEU v CHS

```{r}
ggplot(data = dplyr::filter(plot_df, z_score <= 0), aes(al_freq_CEU, al_freq_CHS, colour = z_score)) +
  geom_point() +
  scale_color_viridis_c() +
  coord_fixed() +
  geom_smooth(se = F) +
  geom_abline(intercept = 0, slope = 1) +
  ggtitle("IQ-negative alleles")

ggplot(data = dplyr::filter(plot_df, z_score >= 0), aes(al_freq_CEU, al_freq_CHS, colour = z_score)) +
  geom_point() +
  scale_color_viridis_c() +
  coord_fixed() +
  geom_smooth(se = F) +
  geom_abline(intercept = 0, slope = 1) +
  ggtitle("IQ-positive alleles")
```

## Run Fst

```{r}
fst_out <- as.data.frame(pegas::Fst(snp_hits, pop = populations))

# make rownames into separate column
fst_out$rsid <- rownames(fst_out)

# join to snp_al_nos DF
test <- dplyr::left_join(snp_al_nos,
                         dplyr::select(fst_out, rsid, Fst),
                         by = c("SNP" = "rsid"))

# plot
ggplot(test, aes(SNP, Fst)) +
  geom_point() +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90))
```

## Identify SNPs with Fst above 0.2

```{r}
high_fst_snps <- test$SNP[test$Fst > 0.2]
```

## Plot above with labels for these SNPs

```{r}
library(ggrepel)
ggplot(data = dplyr::filter(plot_df, z_score <= 0), aes(al_freq_YRI, al_freq_CEU, colour = z_score, label = rsid)) +
  geom_point() +
  geom_label_repel(aes(label = ifelse(rsid %in% high_fst_snps, rsid, ''), )) +
  #geom_text(aes(label = ifelse(rsid %in% high_fst_snps, rsid, '')), hjust = 0, vjust = 0, colour = "black") +
  scale_color_viridis_c() +
  coord_fixed() +
  geom_smooth(se = F) +
  geom_abline(intercept = 0, slope = 1) +
  ggtitle("IQ-negative alleles")

ggplot(data = dplyr::filter(plot_df, z_score >= 0), aes(al_freq_YRI, al_freq_CEU, colour = z_score)) +
  geom_point() +
  scale_color_viridis_c() +
  coord_fixed() +
  geom_smooth(se = F) +
  geom_abline(intercept = 0, slope = 1) +
  ggtitle("IQ-positive alleles")
```

# Run again on SNPs from *Lee et al (2019) Gene discovery and polygenic prediction from a genome-wide association study of educational attainment in 1.1 million individuals*

## Pull out SNPs from paper

```{r}
# extract from excel doc
snps_eduyrs <- read_xlsx("~/Documents/Repositories/racist_hypothesis/data/20180723_Lee-et-al_supp-tables.xlsx", sheet = "2. EduYears Lead SNPs", skip = 1, n_max = 1271)
# write table of SNPs
write.table(snps_eduyrs[["SNP"]], "~/Documents/Repositories/racist_hypothesis/data/20200316_snps_eduyears.list", quote = F, row.names = F, col.names = F)
```

## Select those SNPs from the VCF

```{bash}
gatk SelectVariants \
  -R refs/hs37d5.fa.gz \
  -V vcfs/1gk_all.vcf.gz \
  --keep-ids racist_hypothesis/data/20200316_snps_eduyears.list \
  -O vcfs/snphits_eduyrs.vcf.gz
```

# Get more SNPs for height

From the GWAS catalog here: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0004339>. 

Don't include child trait data. Leaves *4907* associations.

Saved here: `~/Documents/Repositories/racist_hypothesis/data/20200304_raw_associations_height.csv`

```{bash}
# pull out rsIDs
cat data/20200304_raw_associations_height.csv | cut -f1 -d'-' > tmp_rsid.txt 
# pull out lines with risk alleles only 
grep "<b>\w</b>" data/20200304_raw_associations_height.csv > data/20200316_raw_associations_height_edited.csv
# pull out rsIDs and paste into edited doc
cut -f1 -d'-' data/20200316_raw_associations_height_edited.csv
# note: split "Variant and risk allele" column into two manually
```

*20200316* 

## Obtain data

A bit messy. Try getting the height SNPs from this paper instead:

Yengo et al. (2018) *Meta-analysis of genome-wide association studies for height and body mass index in approximately 700000 individuals of European ancestry*

Data downloaded from here:
<https://portals.broadinstitute.org/collaboration/giant/index.php/GIANT_consortium_data_files>
More specifically: <https://portals.broadinstitute.org/collaboration/giant/images/e/e2/Meta-analysis_Locke_et_al%2BUKBiobank_2018_top_941_from_COJO_analysis_UPDATED.txt.gz> 

```{bash}
cd racist_hypothesis/data
# download
wget https://portals.broadinstitute.org/collaboration/giant/images/e/e2/Meta-analysis_Locke_et_al%2BUKBiobank_2018_top_941_from_COJO_analysis_UPDATED.txt.gz
# unzip
gunzip Meta-analysis_Locke_et_al%2BUKBiobank_2018_top_941_from_COJO_analysis_UPDATED.txt.gz
# rename
mv Meta-analysis_Wood_et_al+UKBiobank_2018_top_3290_from_COJO_analysis.txt 20181015_Yengo-et-al_snps_height.txt

```

## Pull out list of SNPs

```{bash}
cut -f1 20181015_Yengo-et-al_snps_height.txt | tail -n+2 > 20200318_snps_height.list
```

## Extract calls for those SNPs from VCF

```{bash}
gatk SelectVariants \
  -R refs/hs37d5.fa.gz \
  -V vcfs/1gk_all.vcf.gz \
  --keep-ids racist_hypothesis/data/20200318_snps_height.list \
  -O vcfs/snphits_height.vcf.gz
```

*20200318*

Get SNPs for IBD.

*Huang et al. (2017) Fine-mapping inflammatory bowel disease loci to single-variant resolution*

Data downloaded here: <https://www.nature.com/articles/nature22969#Sec29>.
More specifically, Supplementary Table 1: <https://static-content.springer.com/esm/art%3A10.1038%2Fnature22969/MediaObjects/41586_2017_BFnature22969_MOESM2_ESM.xlsx>
Saved here: `data/20170628_Huang-et-al_supp-table-1.xlsx`

## Pull out SNPs from paper

```{r}
# extract from excel doc
snps_ibd <- read_xlsx(path = here::here("data", "20170628_Huang-et-al_supp-table-1.xlsx"),
                      sheet = "list of variants", )
snps_ibd_csl <- read_xlsx(path = here::here("data", "20170628_Huang-et-al_supp-table-1.xlsx"),
                          sheet = "list of credible sets", )
# write tables of SNPs
write.table(x = snps_ibd$variant,
            file = here::here("data", "20200319_snps_ibd.list"),
            quote = F,
            row.names = F,
            col.names = F)
write.table(x = snps_ibd_csl$variant.lead,
            file = here::here("data", "20200319_snps_ibd_csl.list"),
            quote = F,
            row.names = F,
            col.names = F)
```

## Get VCFs

```{bash}
gatk SelectVariants \
  -R refs/hs37d5.fa.gz \
  -V vcfs/1gk_all.vcf.gz \
  --keep-ids racist_hypothesis/data/20200319_snps_ibd_csl.list \
  -O vcfs/snphits_ibd.vcf.gz
```

## Copy VCFs for all into data folder

```{bash}
cp vcfs/snphits* racist_hypothesis/data
```

*20200320*

# Analysis Proper

## Import 1GK metadata (for population)

From here: <http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/working/20130606_sample_info/20130606_sample_info.xlsx> (link embedded in this page: <www.internationalgenome.org/data>)

```{r}
meta <- read_xlsx(here::here("data", "20130606_sample_info.xlsx"), sheet = "Sample Info") %>% dplyr::select(Sample, Population, Gender)
```

## Read in VCFs with allele counts for target SNPs

```{r}
# list target VCFs
target_vcfs <- list.files(here::here("data"),
                          pattern = glob2rx("snphits_*.gz"), 
                          full.names = T)

# read in VCFs and get allele counts
vcf_list <- lapply(target_vcfs, function(vcf_file){
  # read in VCFs
  vcf_out <- pegas::read.vcf(vcf_file)
  # create population column
  populations <- unlist(lapply(rownames(vcf_out), function(sample){
  meta$Population[meta$Sample == sample]
  }))
  vcf_out$population <- populations
  # reorder
  vcf_out <- vcf_out %>% dplyr::select(population, everything())
  # split by population
  vcf_out_split <- split(vcf_out, f = vcf_out$population)
  # remove population columns
  vcf_out_split <- lapply(vcf_out_split, function(x){
    x$population <- NULL
    return(x)
  })
  # get allele counts
  allele_counts <- lapply(vcf_out_split, function(population){
    summary(population)
  })
  return(allele_counts)
})
# set names
names(vcf_list) <- gsub("snphits_|.vcf.gz", "", list.files(here::here("data"), pattern = glob2rx("snphits_*.gz")))


```

## Read in SNP data

**NOTE**:

• In the *Lee et al.* (edu_years) data tables, the sheet says: "Notes: Clumping of GWAS results was performed as described in the Supplementary Notes. SNPs are ordered by P-value. Chromosome (CHR) and base pair (BP) positions are reported for human genome build 37 (hg19). *"Allele 1" is the allele whose estimated effect size (Beta) and allele frequency are reported.* Standard errors (SE) and P-values are derived from test statistics that have been adjusted by an estimated LDSC intercept of 1.113. The analysis is based on 10,016,265 SNPs. The average chi-squared statistic is 2.530/2.816 (adjusted and unadjusted, respectively) and lambda GC is 2.038 (unadjusted)."

• In the *Yengo et al.* (height) data tables, the header is self-explanatory.

• In the *Huang et al.* (ibd) data tables, the SNPs have odds ratios rather than betas. Also, the legend says that *A0 is the reference allele and A1 is the tested allele*. p_multi is the -log10(P-value) for multi-variate model.

```{r}
# create empty list
snps_list <- list()
# add edu_years SNPs
snps_list[["edu_years"]] <- read_xlsx(here::here("data", "20180723_Lee-et-al_supp-tables.xlsx"), sheet = "2. EduYears Lead SNPs", skip = 1, n_max = 1271) %>% 
  dplyr::select(snp = "SNP", 
                tested_allele = "Allele 1", 
                other_allele = "Allele2", 
                effect_size = "Effect size", 
                p_value = "P-value")
# add height SNPs
snps_list[["height"]] <- read_delim(here::here("data", "20181015_Yengo-et-al_snps_height.txt"), delim = "\t") %>% 
  dplyr::select(snp = "SNP", 
                tested_allele = "Tested_Allele", 
                other_allele = "Other_Allele", 
                effect_size = "BETA", 
                p_value = "P")
# add ibd SNPS - note the "effect size" here is the mean odds ratio across both CD and UC
snps_list[["ibd"]] <- read_xlsx(here::here("data", "20170628_Huang-et-al_supp-table-1.xlsx"), sheet = "list of credible sets") %>% 
  dplyr::mutate(mean_or = (OR_CD + OR_UC) / 2) %>% 
  dplyr::select(snp = "variant.lead", 
                tested_allele = "A1", 
                other_allele = "A0", 
                effect_size =  "mean_or",
                p_value = "p_multi")
```

## Create data frames with allel frequencies

```{r}
# TEST
test_vcf_popn <- vcf_list$snphits_eduyrs.vcf.gz$ACB$rs780569
test_snps <- snps_list$edu_years 

snp_id <- names(test_vcf_popn)[1]
# create final DF
final_df <- data.frame("allele" = names(test_vcf_popn$allele),
                       "count" = test_vcf_popn$allele,
                       stringsAsFactors = F)
# get allele frequency
final_df$al_freq <- final_df$count / sum(final_df$count)
# pull out effect sizes and p-values from snp_df
effect_sizes <- data.frame("allele" = c(test_snps$other_allele[test_snps$snp == snp_id],
                                        test_snps$tested_allele[test_snps$snp == snp_id]),
                           "effect_size" = c(0, test_snps$effect_size[test_snps$snp == snp_id]),
                           "p_value" = c(0, test_snps$p_value[test_snps$snp == snp_id]),
                           stringsAsFactors = F)

# Create function
get_alfreq_table <- function(population, snp_df){
  counter <- 0
  population <- lapply(population, function(snp_summary){
    # set counter and extract SNP ID
    counter <<- counter + 1
    snp_id <- names(population)[counter]
    # create final DF
    final_df <- data.frame("allele" = names(snp_summary$allele),
                           "count" = snp_summary$allele,
                           stringsAsFactors = F)
    # get allele frequency
    final_df$al_freq <- final_df$count / sum(final_df$count)
    # pull out effect sizes and p-values from snp_df
    effect_sizes <- data.frame("allele" = c(snp_df$other_allele[snp_df$snp == snp_id],
                                            snp_df$tested_allele[snp_df$snp == snp_id]),
                               "effect_size" = c(0, snp_df$effect_size[snp_df$snp == snp_id]),
                               "p_value" = c(0, snp_df$p_value[snp_df$snp == snp_id]),
                               stringsAsFactors = F)
    # join DFs. Note that it only joins the two alleles in the snp_df
    final_df <- dplyr::left_join(final_df, effect_sizes, by = "allele")
    return(final_df)
  })
  return(population)
}

test <- get_alfreq_table(vcf_list$snphits_eduyrs.vcf.gz$ACB, snp_df = snps_list$edu_years)
# works
test <- lapply(vcf_list$snphits_eduyrs.vcf.gz, function(population){
  get_alfreq_table(population, snps_list$edu_years)
})
# works
test_height <- lapply(vcf_list$snphits_height.vcf.gz, function(population){
  get_alfreq_table(population, snps_list$height)
})
# Error in data.frame(allele = c(snp_df$other_allele[snp_df$snp == snp_id],  : arguments imply differing number of rows: 0, 1
# Find out if all SNPs are in both DFs
which(names(vcf_list$snphits_height.vcf.gz$ACB) %in% snps_list$height$snp == F)
# [1]  466 2002
# adjust function so that it only takes SNPs that are in both DFs
get_alfreq_table <- function(population, snp_df){
  # take only the SNPs that are also in the snp_df
  indexes_to_keep <- which(names(population) %in% snp_df$snp == T)
  population <- population[indexes_to_keep]
  # start loop
  counter <- 0
  population <- lapply(population, function(snp_summary){
    # set counter and extract SNP ID
    counter <<- counter + 1
    snp_id <- names(population)[counter]
    # create final DF
    final_df <- data.frame("allele" = names(snp_summary$allele),
                           "count" = snp_summary$allele,
                           stringsAsFactors = F)
    # get allele frequency
    final_df$al_freq <- final_df$count / sum(final_df$count)
    # pull out effect sizes and p-values from snp_df
    effect_sizes <- data.frame("allele" = c(snp_df$other_allele[snp_df$snp == snp_id],
                                            snp_df$tested_allele[snp_df$snp == snp_id]),
                               "effect_size" = c(0, snp_df$effect_size[snp_df$snp == snp_id]),
                               "p_value" = c(0, snp_df$p_value[snp_df$snp == snp_id]),
                               stringsAsFactors = F)
    # join DFs. Note that it only joins the two alleles in the snp_df
    final_df <- dplyr::left_join(final_df, effect_sizes, by = "allele")
    return(final_df)
  })
  return(population)
}

## Need to adjust effect_size direct within this function
test2 <- lapply(test_alcnts, function(x){
  if(any(x$effect_size < 0)){
    x$effect_size[x$effect_size == 0] <- x$effect_size[x$effect_size < 0] * (-1)
    x$effect_size[x$effect_size < 0] <- 0
    return(x)
  }
  else {
    return(x)
  }
})
# WORKS
test <- test_alcnts[[1]]
if(any(test$effect_size < 0)){
  test$effect_size[test$effect_size == 0] <- test$effect_size[test$effect_size < 0] * (-1)
  test$effect_size[test$effect_size < 0] <- 0
}
# Incorporate into function:
get_alfreq_table <- function(population, snp_df){
  # take only the SNPs that are also in the snp_df
  indexes_to_keep <- which(names(population) %in% snp_df$snp == T)
  population <- population[indexes_to_keep]
  # start loop
  counter <- 0
  population <- lapply(population, function(snp_summary){
    # set counter and extract SNP ID
    counter <<- counter + 1
    snp_id <- names(population)[counter]
    # create final DF
    final_df <- data.frame("allele" = names(snp_summary$allele),
                           "count" = snp_summary$allele,
                           stringsAsFactors = F)
    # get allele frequency
    final_df$al_freq <- final_df$count / sum(final_df$count)
    # pull out effect sizes and p-values from snp_df
    effect_sizes <- data.frame("allele" = c(snp_df$other_allele[snp_df$snp == snp_id],
                                            snp_df$tested_allele[snp_df$snp == snp_id]),
                               "effect_size" = c(0, snp_df$effect_size[snp_df$snp == snp_id]),
                               "p_value" = c(0, snp_df$p_value[snp_df$snp == snp_id]),
                               stringsAsFactors = F)
    # join DFs. Note that it only joins the two alleles in the snp_df
    final_df <- dplyr::left_join(final_df, effect_sizes, by = "allele")
    # remove any rows with NA (caused by having a third allele)
    final_df <- final_df[complete.cases(final_df), ]
    # turn all negative effects sizes into positive ones
    if(any(final_df$effect_size < 0)){
      final_df$effect_size[final_df$effect_size == 0] <- final_df$effect_size[final_df$effect_size < 0] * (-1)
      final_df$effect_size[final_df$effect_size < 0] <- 0
    }
    return(final_df)
  })
  return(population)
}

# Run over list
counter_new <- 0
alcnt_df_lst <- lapply(vcf_list, function(pheno){
  counter_new <<- counter_new + 1
  lapply(pheno, function(x){
    out <- get_alfreq_table(population = x, snp_df = snps_list[[counter_new]])
    final <- dplyr::bind_rows(out, .id = "snp")
    return(final)
  })
})

# create final DF
alcnt_df <- lapply(alcnt_df_lst, function(pheno){
  dplyr::bind_rows(pheno, .id = "population")
})

# filter only for alleles with an effect and correct rownames
alcnt_df_filt <- lapply(alcnt_df, function(pheno){
  pheno <- pheno[pheno$effect_size != 0, ]
  rownames(pheno) <- seq(1:nrow(pheno))
  return(pheno)
})  
```

## Create columns for each population

```{r}
plot_df_lst <- lapply(alcnt_df_filt, function(pheno){
  pheno <- pheno %>% dplyr::select(-count)
  pheno <- tidyr::pivot_wider(data = pheno,
                              names_from = population,
                              names_prefix = "al_freq_",
                              values_from = al_freq)
  return(pheno)
})

```


## Plot

### Set up vectors for phenotype-specific parameters

```{r}
# Colour palettes
colour_pals <- c("viridis", "inferno", "plasma")
# Titles
titles <- c("Education in years", "")
```

```{r}
counter <- 0
lapply(plot_df_lst, function(pheno){
  counter <<- counter + 1
  ggplot(pheno, aes(al_freq_YRI, al_freq_CEU, colour = effect_size)) +
    geom_point() +
    scale_color_viridis_c(option = colour_pals[counter]) +
    coord_fixed() +
    geom_smooth(se = F) +
    geom_abline(intercept = 0, slope = 1) +
    xlab("Allele frequency in YRI") +
    ylab("Allele frequency in CEU")
})
```











