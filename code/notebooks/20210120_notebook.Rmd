---
title: "Human traits Fst"
author: "Ian Brettell"
date: "5 January 2021"
#output: html_notebook
#editor_options: 
#  chunk_output_type: inline
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    keep_md: true
    pandoc_args: ["--lua-filter=color-text.lua"]
    highlight: pygments  
---

# Setup

* [Working directory]{color="#4f0943"} on EBI Cluster: `/hps/research1/birney/users/ian/hmn_fst`
* [GitHub repository]{color="#4f0943"}: <https://github.com/brettellebi/human_traits_fst>

## `conda` env on cluster

```{r, engine='bash', eval = F}
# Create env on cluster with mamba
mamba create -y \
  -n fst_env_rhel \
  -c bioconda gatk4
conda activate fst_env_rhel
mamba install bcftools plink2 r-base r-essentials r-tidyverse r-units libgdal r-sf
# Export
conda env export \
  --no-builds \
  -f envs/fst_env_rhel.yml
# Activate
conda activate fst_env_rhel
```

## `renv`

```{r, eval = F}
# Export env (to renv.lock file)
renv::init()
# To install packages on new system, or 'activate' the env: 
renv::restore()
```

## Load libaries

```{r, message = F, warning= F}
library(here)
library(tidyverse)
library(pegas)
library(knitr)
library(plotly)
library(ggridges)
library(qqman)
```

## Set plotting parameters

```{r}
# Create factor levels for `trait`
trait_levels = c("hei", "bmi", "edu", "int", "ibd", "pig")
# Create vector for recoding traits with full names
recode_vec = c("hei" = "Height",
               "bmi" = "BMI",
               "edu" = "Educational attainment",
               "int" = "Intelligence",
               "ibd" = "IBD",
               "pig" = "Pigmentation")
# Colour palette
fill_pal_primary = c("Height" = "#FC4E07",
                     "BMI" = "#FFBF00",
                     "Educational attainment" = "#0BC166",
                     "Intelligence" = "#00AFBB",
                     "IBD" = "#D84797",
                     "Pigmentation" = "#360568")
fill_pal_secondary = c("Height" = "#D11F1F",
                       "BMI" = "#cc7e08",
                       "Educational attainment" = "#39BFA2",
                       "Intelligence" = "#02395c",
                       "IBD" = "#82043B",
                       "Pigmentation" = "#960592")
```

## Download 1GK data

### Download from FTP

```{r, engine='bash', eval = F}
wget \
  -r -p -k \
  --no-parent \
  -cut-dirs=5 \
  ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/
```

### Put filenames into list

```{r, engine='bash', eval = F}
find vcfs/ftp.1000genomes.ebi.ac.uk/ALL.chr*.vcf.gz \
  > human_traits_fst/data/20200205_vcfs.list
```

### Merge VCFs

```{r, engine='bash', eval = F}
java -jar /nfs/software/birney/picard-2.9.0/picard.jar MergeVcfs \
  I=human_traits_fst/data/20200205_vcfs.list \
  O=vcfs/1gk_all.vcf.gz
# Exception in thread "main" java.lang.IllegalArgumentException: The contig entries in input file /hps/research1/birney/users/ian/rac_hyp/vcfs/ftp.1000genomes.ebi.ac.uk/ALL.chrMT.phase3_callmom-v0_4.20130502.genotypes.vcf.gz are not compatible with the others.

# So remove that one from list above
sed -i '/MT/d' human_traits_fst/data/20200205_vcfs.list

# run MergeVCFs again
java -jar /nfs/software/birney/picard-2.9.0/picard.jar MergeVcfs \
  I=human_traits_fst/data/20200205_vcfs.list \
  O=vcfs/1gk_all.vcf.gz
  
# Exception in thread "main" java.lang.IllegalArgumentException: The contig entries in input file /hps/research1/birney/users/ian/rac_hyp/vcfs/ftp.1000genomes.ebi.ac.uk/ALL.chrY.phase3_integrated_v2a.20130502.genotypes.vcf.gz are not compatible with the others.
sed -i '/chrY/d' human_traits_fst/data/20200205_vcfs.list

# run MergeVCFs again
java -jar /nfs/software/birney/picard-2.9.0/picard.jar MergeVcfs \
  I=human_traits_fst/data/20200205_vcfs.list \
  O=vcfs/1gk_all.vcf.gz
# SUCCESS
```

## Obtain GWAS data from the GWAS Catalog <https://www.ebi.ac.uk/gwas>

### Pull data for each trait

All documents downloaded via 'Download Catalog data' link, then collated and saved here: `data/20210119_gwas-catalog.xlsx`

#### Height

* height: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0004339>
  - **4960 SNPs** from **54 studies**
  
#### BMI

* bmi: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0004340>
  - **7801 SNPs** from **182 studies**
  
#### Educational attainment

* self reported educational attainment: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0004784>
  - **3989 SNPs** from **24 studies**
  
#### Intelligence

* intelligence: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0004337>
  - **2967 SNPs** from **27 studies**
  
#### IBD

* inflammatory bowel disease: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0003767>
  - **1886 SNPs** from **110 studies**

#### Pigmentation

* skin pigmentation: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0003784>
  - **217 SNPs** from **15 studies**

* skin pigmentation measurement: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0007009>
  - **236 SNPs** from **10 studies**

* eye color: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0003949>
  - **77 SNPs** from **13 studies**
  
* eye colour measurement:
<https://www.ebi.ac.uk/gwas/efotraits/EFO_0009764>
  - **202 SNPs** from **9 studies**
  
* hair color: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0003924>
  - **424 SNPs** from **18 studies**
  
* hair colour measurement: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0007822>
  - **541 SNPs** from **6 studies**
  
* hair shape measurement: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0007824>
  - **20 SNPs** from **2 studies**

### Read into list

```{r}
file_name = "20210119_gwas-catalog.xlsx"
# Create vector of traits
traits = c("hei", "bmi", "edu", "int", "ibd", "pig")
names(traits) = traits
# Assign sheets to traits
sheets <- seq(1:11)
names(sheets) <- c("hei", "bmi", "edu", "int", "ibd", rep("pig", 6))

# get sheets
sheet_names <- readxl::excel_sheets(here::here("data", file_name))

# Create function to read in data
read_catalog_data <- function(path, target_sheet){
  # Read in data
  out = readxl::read_xlsx(path, sheet = target_sheet) %>% 
    dplyr::select(CHR = CHR_ID, 
                  POS = CHR_POS, 
                  SNP_AL = `STRONGEST SNP-RISK ALLELE`, 
                  P = `P-VALUE`, 
                  OR_OR_BETA = `OR or BETA`, 
                  MAPPED_TRAIT,
                  STUDY = `STUDY ACCESSION`) %>% 
    # Split SNP and risk allele into separate columns
    dplyr::mutate(TOP_SNP = stringr::str_split(SNP_AL, "-", simplify = T)[, 1],
                  RISK_ALLELE = stringr::str_split(SNP_AL, "-", simplify = T)[, 2]) %>% 
    # Reorder and select
    dplyr::select(CHR, POS, TOP_SNP, RISK_ALLELE, P, OR_OR_BETA, MAPPED_TRAIT, STUDY)
  # Change variables to specific types
  out$CHR <- as.integer(out$CHR)
  out$POS <- as.numeric(out$POS)
  out$P <- as.numeric(out$P)
  # return DF
  return(out)
}

# Read in data
counter <- 0
dat_lst = lapply(traits, function(trait){
  # set counter 
  counter <<- counter + 1
  # set target file
  target_file = here::here("data", file_name)
  # get target sheet
  target_sheet = sheets[names(sheets) == trait]
  length(target_sheet)
  # read in pigmentation data from multiple sheets and bind into single DF
  if (length(target_sheet) > 1){
    # loop over each sheet
    df <- lapply(target_sheet, function(sheet){
      out <- read_catalog_data(target_file,
                               target_sheet = sheet)
    })
    # set name of each DF to name of sheet (replacing spaces with underscores)
    names(df) = sheet_names[target_sheet] %>% 
      stringr::str_replace_all(" ", "_")
    # bind DFs into single DF
    df <- dplyr::bind_rows(df, .id = "PIG_PHENO")
  } 
  else {
    # read in other data
    df <- read_catalog_data(target_file,
                            target_sheet = target_sheet)
  }
  # Set PHENO column
  df$PHENO <- factor(trait, levels = trait_levels)
  # Recode PHENO
  df$PHENO = dplyr::recode(df$PHENO, !!!recode_vec)
  # Create list
  out = list()
  # Return DF as "raw"
  out[["raw"]] = df
  
  return(out)
})

# How many SNPs in raw data
lapply(dat_lst, function(x) nrow(x[["raw"]]))

# Clean data
dat_lst = lapply(dat_lst, function(pheno){
  df_clean = pheno[["raw"]]
  # Remove rows with p-value of 0 (only 32 of them, associated with suntan)
  df_clean = df_clean[df_clean$P != 0, ]
  # Remove rows with NA in CHR
  df_clean = df_clean[!is.na(df_clean$CHR), ]
  # Remove duplicates
  ## Find SNPs that are duplicated
  dupes = unique(df_clean$TOP_SNP[duplicated(df_clean$TOP_SNP) | duplicated(df_clean$TOP_SNP, fromLast = T)])
  ## Select only 1 SNP from each set of duplicated SNPs
  dupe_filt = lapply(dupes, function(dupe){
    # Take the one with the lowest P-value
    min_p = min(df_clean$P[df_clean$TOP_SNP == dupe])
    out = df_clean[df_clean$TOP_SNP == dupe & df_clean$P == min_p, ]
    # If there are still duplicates due to having equal P, take the one with the largest effect size
    if (nrow(out) > 1 ){
      out = out[which.max(out$OR_OR_BETA), ]
    }
    return(out)
  })
  # Bind list into DF
  dupe_filt = dplyr::bind_rows(dupe_filt)
  # Extract non-duplicated rows
  non_dupe = df_clean[!duplicated(df_clean$TOP_SNP) & !duplicated(df_clean$TOP_SNP, fromLast = T), ]
  # Bind non-duplicated rows with filtered duplicates
  df_clean = rbind(non_dupe, dupe_filt) 
  # Add to list
  pheno[["clean"]] = df_clean
  
  return(pheno)
})

# New SNP count
lapply(dat_lst, function(x) nrow(x[["clean"]]))
```

```{r}
lapply(dat_lst, function(pheno){
  knitr::kable(head(pheno[["clean"]]))
})
```


### Generate Manhattan plots

Create function for Manhattan plotting

```{r}
get_man <- function(df, trait, chr, bp, snp, p){
  # Set title with number of SNPs
  title <- paste(trait, "\n", "SNP count:", nrow(df))
  # Plot
  manhattan(df, chr=chr, bp=bp, snp=snp, p=p,
            cex = 0.6,
            c(fill_pal_primary[names(fill_pal_primary) == trait],
              fill_pal_secondary[names(fill_pal_secondary) == trait]),
            main = title)
}
```

Plot

```{r}
# Create function to plot
counter = 0
lapply(dat_lst, function(pheno_df){
  # set counter
  counter <<- counter + 1
  df = pheno_df[["clean"]]
  trait = unique(df$PHENO)
  # Get title
  title <- paste(trait, "\n", "SNP count:", nrow(df))
  # Plot
  get_man(df, trait = trait, chr = "CHR", bp = "POS", snp = "TOP_SNP", p = "P")
})
```

Save

```{r, eval = F}
counter = 0
lapply(dat_lst, function(pheno_df){

  # set counter
  counter <<- counter + 1
  df = pheno_df[["clean"]]
  trait = unique(df$PHENO)
  # Get title
  title <- paste(trait, "\n", "SNP count:", nrow(df))
  # Set file name to save
  file = file.path(here::here("plots"),
                   paste("manhattan_",
                         names(dat_lst)[counter],
                         ".svg",
                         sep = ""))
  # Set up graphics device
  svg(file,
      width = 10,
      height = 6)  
  
  # Plot
  get_man(df, trait = trait, chr = "CHR", bp = "POS", snp = "TOP_SNP", p = "P")
  
  dev.off()
})
```

#### How many have *P* < 1e-08?

```{r}
lapply(dat_lst, function(pheno_df){
  length(which(pheno_df[["clean"]]$P < 1e-08 ))
})
```

#### Create list of target SNPs to extract from 1KG

```{r, eval = F}
# Just SNPs for extracting from 1KG
counter <- 0
lapply(dat_lst, function(pheno){
  df = pheno[["clean"]]
  # Set counter
  counter <<- counter + 1
  # Set file basename
  trait = names(dat_lst)[counter]
  filename = paste("20210119_snps_", trait, ".list", sep = "")
  # Write SNPs to file
  readr::write_lines(df$TOP_SNP, here("data", filename))
})

# SNP and P with header for clumping
counter <- 0
lapply(dat_lst, function(pheno){
  df = pheno[["clean"]]
  # Set counter
  counter <<- counter + 1
  # Set file basename
  trait = names(dat_lst)[counter]
  filename = paste("20210120_snps_", trait, "_with_P.txt", sep = "")
  # Write SNPs to file
  df %>% 
    dplyr::select(SNP = TOP_SNP, P) %>% 
    readr::write_tsv(here("data", filename))
})
```

## Filter 1KG VCF for target SNPs

```{r, engine='bash', eval = F}

traits=$(echo hei bmi edu int ibd pig)

for trait in $(echo $traits ); do
  bsub \
    -M 10000 \
    -o log/20210120_extract_snps_$trait.out \
    -e log/20210120_extract_snps_$trait.err \
    """
    conda activate fst_env_rhel ;
    gatk SelectVariants \
      -R refs/hs37d5.fa.gz \
      -V vcfs/1gk_all.vcf.gz \
      --keep-ids human_traits_fst/data/20210119_snps_$trait.list \
      -O vcfs/snphits_$trait.vcf.gz 
    """ ;
done
```

## Clump with `Plink1.9`

From the `Plink1.7` documentation (<http://zzz.bwh.harvard.edu/plink/clump.shtml>):

> The clumping procedure takes all SNPs that are significant at threshold p1 that have not already been clumped (denoting these as index SNPs) and forms clumps of all other SNPs that are within a certain kb distance from the index SNP (default 250kb) and that are in linkage disequilibrium with the index SNP, based on an r-squared threshold (default 0.50)... This is a greedy algorithm and so each SNP will only appear in a single clump, if at all. 

> ...[t]he TOTAL field lists all SNPs that are clumped with the index SNP, irrespective of the p-value for those SNPs. This number is then split into those clumped SNPs that are not significant (p>0.05) and various other groups defined by significance thresholds. For SNPs that are significant at the p2 threshold, they are listed explicitly. The (1) after each SNP name refers to the results file they came from (in this case, there is only a single result file specified, so all values are 1).

So here, we're taking all SNPs with *P* < 1e-08 as index SNPs, and it will explicitly list all SNPs within the clump that also meets that threshold. 

```{bash}

conda activate fst_env_rhel

out_dir=human_traits_fst/data/20210120_clumped
mkdir -p $out_dir

traits=$(echo hei bmi edu int ibd pig)

# Run with different parameters

for trait in $(echo $traits ); do
  for r2 in $(echo 0.5 0.7 0.9 ) ; do
    for kb in $(echo 250 500 1000 ) ; do
      bsub \
        -o log/20210120_clump_$trait\_$r2\_$kb.out \
        -e log/20210120_clump_$trait\_$r2\_$kb.err \
        """
        conda activate fst_env_rhel ;
        plink \
          --vcf vcfs/snphits_$trait.vcf.gz \
          --clump human_traits_fst/data/20210120_snps_$trait\_with_P.txt \
          --clump-p1 0.00000001 \
          --clump-p2 0.00000001 \
          --clump-r2 $r2 \
          --clump-kb $kb \
          --out $out_dir/$trait\_r2-$r2\_kb-$kb 
        """  ;
    done ;
  done;  
done

```

## Get allele frequencies of SNP hits with `Plink2`

### Import 1GK metadata (for sample-population key)

Downloded via this page: <http://www.internationalgenome.org/data>
Download link: <http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/working/20130606_sample_info/20130606_sample_info.xlsx>. 

Saved here: `data/20130606_sample_info.xlsx`

```{r, warning=FALSE, results = 'asis'}
meta = readxl::read_xlsx(here::here("data", "20130606_sample_info.xlsx"),
                          sheet = "Sample Info") %>%
  dplyr::select(Sample, Population, Gender)
knitr::kable(head(meta))
```

### Write population file for Plink2

```{r, eval = F}
write.table(meta[, 1:2],
            here::here("data", "plink2_sample_popn_key.txt"),
            quote = F,
            sep = "\t",
            row.names = F,
            col.names = F)
```

### Run `Plink2` for SNP hits

```{r, engine='bash', eval = F}

conda activate fst_env_rhel

# Set up directories
mkdir -p human_traits_fst/data/20210120_plink2_alfreqs

out_dir=human_traits_fst/data/20210120_plink2_alfreqs

traits=$(echo hei bmi edu int ibd pig)

for trait in $(echo $traits); do
  mkdir -p $out_dir/$trait; 
done   

# Run Plink2

## Get AF per population
for trait in $(echo $traits); do
  plink2 \
    --vcf vcfs/snphits_$trait.vcf.gz \
    --freq \
    --max-alleles 2 \
    --pheno iid-only human_traits_fst/data/plink2_sample_popn_key.txt \
    --loop-cats PHENO1 \
    --out $out_dir/$trait/$trait ;
done

## Get global AF
for trait in $(echo $traits); do
  plink2 \
    --vcf vcfs/snphits_$trait.vcf.gz \
    --freq \
    --max-alleles 2 \
    --out $out_dir/$trait/$trait.all
done

```

## Compare MAF distributions

### Add clumped SNP files

```{r}
target_dir = here::here("data", "20210120_clumped")

counter <- 0
dat_lst = lapply(dat_lst, function(pheno){
  # set counter 
  counter <<- counter + 1
  # get trait name
  trait = names(dat_lst)[counter]
  # get file path
  target_path = file.path(target_dir, paste(trait, ".clumped", sep = ""))
  # read in data
  clumped_df = read.table(target_path,header = T)
  # add to list
  pheno[["clumped"]]  = clumped_df
  
  return(pheno)
})
```

### Add allele frequency files

```{r}
target_dir = here::here("data", "20210120_plink2_alfreqs")

counter <- 0
dat_lst = lapply(dat_lst, function(pheno){
  # set counter 
  counter <<- counter + 1
  # get trait name
  trait = names(dat_lst)[counter]
  # get file path
  target_path = file.path(target_dir, trait, paste(trait, ".all.afreq", sep = ""))
  # read in data
  clean_af = read.table(target_path, header = T, comment.char = "")
  # add to list
  pheno[["clean_af"]] = clean_af
  
  return(pheno)
})
```

### Convert to MAJ/MIN alleles to get MAF

```{r}
dat_lst = lapply(dat_lst, function(pheno){
  df = pheno[["clean_af"]]
  # convert to MAF
  df = df %>% 
    dplyr::mutate(MAJ = if_else(ALT_FREQS <= 0.5,
                                REF,
                                ALT),
                  MIN = ifelse(ALT_FREQS <= 0.5,
                               ALT,
                               REF),
                  MAF = ifelse(ALT_FREQS <= 0.5,
                               ALT_FREQS,
                               1 - ALT_FREQS))
  pheno[["clean_af"]] = df
  
  return(pheno)
})
```


### Histograms of the global MAF distributions (i.e. all 26 populations together)

```{r}
# Extract clean_af DFs
alfreq_list_glob = lapply(dat_lst, function(pheno) pheno[["clean_af"]])

# Merge into single Df
alfreq_glob_df = dplyr::bind_rows(alfreq_list_glob, .id = "trait")

# Make `trait` a factor
alfreq_glob_df$trait = factor(alfreq_glob_df$trait, levels = trait_levels)
# Recode traits for plotting
alfreq_glob_df$trait = dplyr::recode(alfreq_glob_df$trait, !!!recode_vec)
```

Plot
```{r, fig.height=4, fig.width=6.5}
alfreq_glob_df %>% 
  ggplot(aes(MAF, fill = trait)) +
    geom_histogram(bins = 50) +
    scale_fill_manual(values = fill_pal_primary) +
    facet_wrap(~trait, nrow = 2) +
    guides(fill = F) +
    theme_bw() +
    ggtitle("MAF distributions (all 1KG populations combined)")
```

```{r, eval = F}
# Save
ggsave(here("plots", "20210114_global_maf_distributions.svg"),
       device = "svg",
       units = "cm",
       dpi = 400,
       height = 12,
       width = 19.5)
```

## Set up negative controls

Pull out random SNPs with the same global allele frequencies as the GWAS SNP-hits

### Bin SNP hits by allele frequency

Bind to clean DF to get AFs of risk allele

```{r}
dat_lst = lapply(dat_lst, function(pheno){
  # join DFs
  df = dplyr::left_join(pheno[["clean"]],
                        dplyr::select(pheno[["clean_af"]],
                                      -X.CHROM),
                        by = c("TOP_SNP" = "ID"))
  # get AF of risk allele
  df$RISK_AF = dplyr::if_else(df$RISK_ALLELE == df$ALT,
                              df$ALT_FREQS,
                              1 - df$ALT_FREQS)
  # add to list
  pheno[["consol"]] = df
  
  return(pheno)
})
```

Plot RISK_AF against OR_OR_BETA

```{r}
af_plot = lapply(dat_lst, function(pheno) pheno[["consol"]])
af_plot  = dplyr::bind_rows(af_plot)
```

```{r}

af_plot %>% 
  ggplot() +
    geom_point(aes(RISK_AF, OR_OR_BETA, colour = PHENO)) +
    scale_colour_manual(values = fill_pal_primary) +
    facet_wrap(~PHENO, nrow = 2) +
    guides(colour = F, alpha = F) +
    theme_bw() +
    ggtitle("Risk allele frequency vs effect size (OR or beta)")

# Zoom in
af_plot %>% 
  ggplot() +
    geom_point(aes(RISK_AF, OR_OR_BETA,
                   colour = PHENO,
                   alpha = 0.1)) +
    scale_colour_manual(values = fill_pal_primary) +
    facet_wrap(~PHENO, nrow = 2) +
    guides(colour = F, alpha = F) +
    theme_bw() +
    ggtitle("Risk allele frequency vs effect size (OR or beta)") +
    ylim(0,20)
```
Looks strange.

Bin by risk allele frequency

```{r}
# 1% intervals
breakpoints = seq(0, 1, 0.01)

dat_lst = lapply(dat_lst, function(pheno){
  # choose DF
  df = pheno[["consol"]]
  # add bins
  df$BIN_100 = cut(df$RISK_AF, breaks = breakpoints, labels = F)
  # save back into list
  pheno[["consol"]] = df
  
  return(pheno)
})

```

Extract key columns and write to file

```{r, eval = F}
# Save list
risk_afs = lapply(dat_lst, function(pheno){
  df = pheno[["consol"]]
  # extract key columns
  df = df %>% 
    dplyr::select(TOP_SNP, BIN_100)
  
  return(df)
}) %>% 
  # bind into DF and drop NAs
  dplyr::bind_rows() %>% 
  tidyr::drop_na()

readr::write_tsv(risk_afs, here::here("data", "20210121_risk_afs.txt"))
```

### Bin 1KG SNPs 

#### Get allele frequencies from 1KG per chromosome

With `Plink2`
```{r, engine='bash', eval=F}
# set output directory
in_file=vcfs/1gk_all.vcf.gz
out_dir=big_data/20210120_alfreqs_all

# Per chromosome
for chr in $(seq 1 22) ; do
  # create allele-freq tables
  bsub \
    -M 10000 \
    -o log/20210120_plink_alfreq_$chr.out \
    -e log/20210120_plink_alfreq_$chr.err \
    """
    conda activate fst_env_rhel ;
    plink2 \
      --vcf $in_file \
      --freq \
      --chr $chr \
      --max-alleles 2 \
      --snps-only \
      --out $out_dir/$chr ";
done 
```

#### Bin them and save to single file

```{r, eval = F}
# On cluster

# Set variables
in_dir = "../big_data/20210120_alfreqs_all"
out_dir = "../big_data/20210120_alfreqs_all_binned"
breakpoints = seq(0, 1, 0.01)

# Load libreary
library(tidyverse)

# Create output directory
dir.create(out_dir)

# Get list of input files
in_files = list.files(in_dir, pattern = ".afreq", full.names = T)

# Read in files, add bins, and write to output
freq_list = lapply(in_files, function(chr_file){
  # get chromosome name
  chr = basename(chr_file) %>% 
    str_split("\\.", simplify = T) %>% 
    subset(select = 1)
  # read in file
  df = read.table(chr_file, header = T, comment.char = "")
  # add bins
  df$bin_20 = cut(df$ALT_FREQS, breaks = breakpoints, labels = F)
  # write file
  readr::write_tsv(df, file = file.path(out_dir, basename(chr_file)))
})

# Combine into single DF
freq_df = dplyr::bind_rows(freq_list)

# Write to file
readr::write_tsv(freq_df, file = file.path(out_dir, "all.afreq"))
```

#### Pull out random SNPs with same AF as trait risk alleles

```{r}
# On cluster

## Load list of target SNPs
neg_cont_list = saveRDS(neg_cont_list, here::here("data", "20210121_neg_cont_list.rds"))

## Get flat list of unique risk allele frequency bins

# Get variables
in_file = "../big_data/20210120_alfreqs_all_binned/all.afreq"

# Load libraries
library(tidyverse)

# Read in 1KG data
freq_df = readr::read_tsv(in_file)
```


## Compare allele frequencies

### Read in data

```{r}
target_dirs <- list.dirs(here::here("data", "20200622_plink2_alfreqs"), recursive = F)

al_freq_lst <- lapply(target_dirs, function(x){
  target_files <- list.files(x, pattern = ".afreq", full.names = T)
  # read in data
  data_lst <- lapply(target_files, function(target_file){
    read.table(target_file,
               header = T,
               comment.char = "")
  })
  # fix names of populations
  names(data_lst) <- gsub(pattern = "edu.|hei.|bmi.|ibd.|pig.|.afreq",
                          replacement = "",
                          x = list.files(x, pattern = ".afreq"))
  return(data_lst)
})

# set names
names(al_freq_lst) <- basename(target_dirs)

# reorder for (1) height, (2) eduyears, (3) ibd, (4) pigmentation
al_freq_lst <- al_freq_lst[c(2, 1, 3, 4)]
```

### Turn into single table for each pheno

```{r}
al_freq_df <- lapply(al_freq_lst, function(pheno){
  out <- dplyr::bind_rows(pheno, .id = "population") %>% 
    tidyr::pivot_wider(id_cols = c(X.CHROM, ID, REF, ALT),
                       names_from = population,
                       values_from = ALT_FREQS)
})
```

### Randomly swap minor allele

```{r}
set.seed(65)
rdm_sds <- sample(1:100, 4)

counter <- 0
al_freq_df_shuff <- lapply(al_freq_df, function(pheno){
  counter <<- counter + 1
  # set seed
  set.seed(rdm_sds[counter])
  # select SNPs to swap (half of total)
  tgt_indcs <- sample(nrow(pheno), nrow(pheno) /2)
  # swap minor alleles
  pheno[tgt_indcs, 5:ncol(pheno)] <- 1 - pheno[tgt_indcs, 5:ncol(pheno)]
  # return pheno
  return(pheno)
})
```

# Analysis



### Read in population frequency data

```{r}
target_dirs <- list.dirs(here::here("data", "20200622_plink2_alfreqs"), recursive = F)

al_freq_lst <- lapply(target_dirs, function(x){
  target_files <- list.files(x, pattern = ".afreq", full.names = T)
  # read in data
  data_lst <- lapply(target_files, function(target_file){
    read.table(target_file,
               header = T,
               comment.char = "")
  })
  # fix names of populations
  names(data_lst) <- gsub(pattern = "edu.|hei.|bmi.|ibd.|pig.|.afreq",
                          replacement = "",
                          x = list.files(x, pattern = ".afreq"))
  return(data_lst)
})

# set names
names(al_freq_lst) <- basename(target_dirs)
```

### Turn into single table for each pheno

```{r}
al_freq_df <- lapply(al_freq_lst, function(pheno){
  out <- dplyr::bind_rows(pheno, .id = "population") %>% 
    tidyr::pivot_wider(id_cols = c(X.CHROM, ID, REF, ALT),
                       names_from = population,
                       values_from = ALT_FREQS)
})
```

### Randomly swap minor allele

```{r}
set.seed(65)
rdm_sds <- sample(1:100, 5)

counter <- 0
al_freq_df_shuff <- lapply(al_freq_df, function(pheno_df){
  counter <<- counter + 1
  # set seed
  set.seed(rdm_sds[counter])
  # select SNPs to swap (half of total)
  tgt_indcs <- sample(nrow(pheno_df), nrow(pheno_df) /2)
  # swap minor alleles
  pheno_df[tgt_indcs, 5:ncol(pheno_df)] <- 1 - pheno_df[tgt_indcs, 5:ncol(pheno_df)]
  # return pheno_df
  return(pheno_df)
})
```

### Bind in to single data frame and save

```{r}
final = dplyr::bind_rows(al_freq_df_shuff, .id = "phenotype")
```

```{r, eval = F}
final %>% 
  readr::write_tsv(here("data", "20210114_pheno_alfreqs.txt.gz"))
```


### Plot

```{r}
# Set up titles vector
titles <- c("Height", "Educational Attainment", "Inflammatory Bowel Disease", "Pigmentation")
```

#### 2D

##### YRI v CHS

```{r, message=F, warning=F}
counter <- 0
lapply(al_freq_df_shuff, function(pheno){
  counter <<- counter + 1
  ggplot(pheno,
         aes(YRI, CHS)) +
    geom_point(size = 0.5) +
    coord_fixed() +
    geom_smooth(se = F, colour = "red") +
    geom_abline(intercept = 0, slope = 1, colour = "blue") +
    xlab("Allele frequency in YRI") +
    ylab("Allele frequency in CHS") +
    labs(title = titles[counter])
})
```

##### YRI v CEU

```{r, message=F, warning=F}
counter <- 0
lapply(al_freq_df_shuff, function(pheno){
  counter <<- counter + 1
  ggplot(pheno,
         aes(YRI, CEU)) +
    geom_point(size = 0.5) +
    coord_fixed() +
    geom_smooth(se = F, colour = "red") +
    geom_abline(intercept = 0, slope = 1, colour = "blue") +
    xlab("Allele frequency in YRI") +
    ylab("Allele frequency in CEU") +
    labs(title = titles[counter])
})
```

#### 3D

```{r, message=F, warning=F}
colourscales <- c("Viridis", "Hot", "Bluered", "Electric")
titles <- c("Height", "Educational Attainment", "IBD", "Skin/hair pigmentation")

counter <- 0
plts <- lapply(al_freq_df_shuff, function(pheno){
  counter <<- counter + 1
  # set graph resolution
  graph_reso <- 0.05
  # get lm for data
  loess_model <- loess(CEU ~ 0 + CHS + YRI, data = pheno)
  # set up axes
  axis_x <- seq(min(pheno$CHS), max(pheno$CHS), by = graph_reso)
  axis_y <- seq(min(pheno$YRI), max(pheno$YRI), by = graph_reso)
  # sample points
  lm_surface <- expand.grid(CHS = axis_x,
                            YRI = axis_y,
                            KEEP.OUT.ATTRS = F)
  lm_surface$CEU <- predict(loess_model, newdata = lm_surface)
  lm_surface <- reshape2::acast(lm_surface, YRI ~ CHS, value.var = "CEU")
  # create plot
  plt <- plot_ly(pheno,
                 x = ~CHS,
                 y = ~YRI,
                 z = ~CEU,
                 type = "scatter3d",
                 mode = "markers",
                 marker = list(size = 2),
                 text = pheno$ID) 
  plt <- add_trace(plt,
                   z = lm_surface,
              x = axis_x,
              y = axis_y,
              type = "surface",
              colorscale = colourscales[counter]) %>% 
    layout(title = titles[counter])
  return(plt)
})

plts$hei
plts$edu
plts$ibd
plts$pig
```

## Fst

### Find target VCFs

```{r}
# list target VCFs
target_vcfs <- list.files(here::here("data"),
                          pattern = glob2rx("snphits_*.gz"), 
                          full.names = T)

# filter for the four we want
target_vcfs <- target_vcfs[grep("eduyrs|height|ibd_full|pig", target_vcfs)]


```

### With all populations

#### Get Fst stats

```{r, message=F, warning=F, results=F}
# Create raw list of variants
vcf_list_raw <- lapply(target_vcfs, function(vcf_file){
  vcf_out <- pegas::read.vcf(vcf_file)
})

# Create vector of populations
populations <- unlist(lapply(rownames(vcf_list_raw[[1]]), function(sample){
  meta$Population[meta$Sample == sample]
}))

# Generate Fst stats
fst_out_lst <- lapply(vcf_list_raw, function(pheno){
  as.data.frame(pegas::Fst(pheno, pop = populations))
})

# make rownames into separate column
fst_out_lst <- lapply(fst_out_lst, function(pheno){
  pheno$snp <- rownames(pheno)
  return(pheno)
})
names(fst_out_lst) <- titles

# bind into single DF
fst_out_df <- dplyr::bind_rows(fst_out_lst, .id = "phenotype")

# Set order of phenotypes
fst_out_df$phenotype <- factor(fst_out_df$phenotype, levels = c("Height", "Educational Attainment", "IBD", "Skin/hair pigmentation"))

head(fst_out_df)
```

#### Plot density

##### 2D

```{r, warning= F}
ggplot(fst_out_df, aes(Fst, fill = phenotype)) +
  geom_density(alpha = 0.7) +
  labs(fill = "Phenotype") +
  ylab("Density") +
  theme_bw() +
  scale_fill_manual(values = c("#E7B800", "#00AFBB", "#360568", "#FC4E07"))
```

##### 3D

```{r, warning = F, message = F}
# factorise 
fst_out_df$phenotype_3d <- factor(fst_out_df$phenotype,
                                    levels = c("Skin/hair pigmentation", "IBD", "Educational Attainment", "Height"))

ggplot() +
  geom_density_ridges2(data = fst_out_df,
                       mapping = aes(x = Fst, y = phenotype_3d, fill = phenotype_3d),
                       scale = 2) +
  scale_fill_manual(values = c("#FC4E07", "#360568", "#00AFBB", "#E7B800")) +
  ylab(label = NULL) +
  theme_bw() +
  guides(fill = guide_legend(reverse=T, 
                             title = "Phenotype")) +
  scale_y_discrete(expand = expand_scale(add = c(0.2, 2.3)))
```

#### Run Kolmogorov-Smirnov Tests

```{r, warning = F}
# Height v EA
ks.test(fst_out_df$Fst[fst_out_df$phenotype == "Height"],
        fst_out_df$Fst[fst_out_df$phenotype == "Educational Attainment"])

# Height v IBD
ks.test(fst_out_df$Fst[fst_out_df$phenotype == "Height"],
        fst_out_df$Fst[fst_out_df$phenotype == "IBD"])

# Height v Pigmentation
ks.test(fst_out_df$Fst[fst_out_df$phenotype == "Height"],
        fst_out_df$Fst[fst_out_df$phenotype == "Skin/hair pigmentation"])
```


### With just YRI, CEU, and CHS

#### Get Fst stats

```{r}
# get samples from target popns only
target_popns <- which(populations %in% c("YRI", "CEU", "CHS"))
populations_3pop <- populations[target_popns]

vcf_list_raw_3pop <- lapply(vcf_list_raw, function(pheno){
  pheno[target_popns, ]
})

# Generate Fst stats
fst_out_lst_3pop <- lapply(vcf_list_raw_3pop, function(pheno){
  as.data.frame(pegas::Fst(pheno, pop = populations_3pop))
})

# make rownames into separate column
fst_out_lst_3pop <- lapply(fst_out_lst_3pop, function(pheno){
  pheno$snp <- rownames(pheno)
  return(pheno)
})
names(fst_out_lst_3pop) <- titles

# bind into single DF
fst_out_df_3pop <- dplyr::bind_rows(fst_out_lst_3pop, .id = "phenotype")
head(fst_out_df_3pop)
```

#### Plot density

##### 2D

```{r, warning=F}
ggplot(fst_out_df_3pop, aes(Fst, fill = phenotype)) +
  geom_density(alpha = 0.7) +
  labs(fill = "Phenotype") +
  ylab("Density") +
  theme_bw() +
  scale_fill_manual(values = c("#E7B800", "#00AFBB", "#360568", "#FC4E07"))
```

##### 3D

```{r, warning=F, message = F}
# factorise 
fst_out_df_3pop$phenotype_3d <- factor(fst_out_df$phenotype,
                                    levels = c("Skin/hair pigmentation", "IBD", "Educational Attainment", "Height"))

ggplot() +
  geom_density_ridges2(data = fst_out_df_3pop,
                       mapping = aes(x = Fst, y = phenotype_3d, fill = phenotype_3d),
                       scale = 2) +
  scale_fill_manual(values = c("#FC4E07", "#360568", "#00AFBB", "#E7B800")) +
  ylab(label = NULL) +
  theme_bw() +
  guides(fill = guide_legend(reverse=T, 
                             title = "Phenotype")) +
  scale_y_discrete(expand = expand_scale(add = c(0.2, 2.3)))
```


#### Run Kolmogorov-Smirnov Tests

```{r, warning = F}
# Height v EA
ks.test(fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "Height"],
        fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "Educational Attainment"])

# Height v IBD
ks.test(fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "Height"],
        fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "IBD"])

# Height v Pigmentation
ks.test(fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "Height"],
        fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "Skin/hair pigmentation"])
```

