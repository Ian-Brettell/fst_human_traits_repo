---
title: "Human traits Fst"
author: "Ian Brettell"
date: "5 January 2021"
#output: html_notebook
#editor_options: 
#  chunk_output_type: inline
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    keep_md: true
    pandoc_args: ["--lua-filter=color-text.lua"]
    highlight: pygments  
---

# Setup

* [Working directory]{color="#4f0943"} on EBI Cluster: `/hps/research1/birney/users/ian/hmn_fst`
* [GitHub repository]{color="#4f0943"}: <https://github.com/brettellebi/human_traits_fst>

## `conda` env on cluster

```{r, engine='bash', eval = F}
# Create env on cluster with mamba
mamba create -y \
  -n fst_env_rhel \
  -c bioconda gatk4
conda activate fst_env_rhel
mamba install bcftools plink2 r-base r-essentials r-tidyverse r-units libgdal r-sf
# Export
conda env export \
  --no-builds \
  -f envs/fst_env_rhel.yml
# Activate
conda activate fst_env_rhel
```

## `renv`

```{r, eval = F}
# Export env (to renv.lock file)
renv::init()
# To install packages on new system, or 'activate' the env: 
renv::restore()
```

## Source libraries, functions and plotting parameters

```{r, warning = F, message = F}
library(here)

source(here::here("code", "scripts", "source.R"))
```

## Download 1GK data

### Download from FTP

```{r, engine='bash', eval = F}
wget \
  -r -p -k \
  --no-parent \
  -cut-dirs=5 \
  ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/
```

### Put filenames into list

```{r, engine='bash', eval = F}
find vcfs/ftp.1000genomes.ebi.ac.uk/ALL.chr*.vcf.gz \
  > human_traits_fst/data/20200205_vcfs.list
```

### Merge VCFs

```{r, engine='bash', eval = F}
java -jar /nfs/software/birney/picard-2.9.0/picard.jar MergeVcfs \
  I=human_traits_fst/data/20200205_vcfs.list \
  O=vcfs/1gk_all.vcf.gz
# Exception in thread "main" java.lang.IllegalArgumentException: The contig entries in input file /hps/research1/birney/users/ian/rac_hyp/vcfs/ftp.1000genomes.ebi.ac.uk/ALL.chrMT.phase3_callmom-v0_4.20130502.genotypes.vcf.gz are not compatible with the others.

# So remove that one from list above
sed -i '/MT/d' human_traits_fst/data/20200205_vcfs.list

# run MergeVCFs again
java -jar /nfs/software/birney/picard-2.9.0/picard.jar MergeVcfs \
  I=human_traits_fst/data/20200205_vcfs.list \
  O=vcfs/1gk_all.vcf.gz
  
# Exception in thread "main" java.lang.IllegalArgumentException: The contig entries in input file /hps/research1/birney/users/ian/rac_hyp/vcfs/ftp.1000genomes.ebi.ac.uk/ALL.chrY.phase3_integrated_v2a.20130502.genotypes.vcf.gz are not compatible with the others.
sed -i '/chrY/d' human_traits_fst/data/20200205_vcfs.list

# run MergeVCFs again
java -jar /nfs/software/birney/picard-2.9.0/picard.jar MergeVcfs \
  I=human_traits_fst/data/20200205_vcfs.list \
  O=vcfs/1gk_all.vcf.gz
# SUCCESS
```

## Obtain GWAS data from the GWAS Catalog <https://www.ebi.ac.uk/gwas>

### Pull data for each trait

[**NOTE**]{colour = "red"}: Uncheck `Include child trait data` before downloading.

All documents downloaded via 'Download Catalog data' link, then collated and saved here: `data/20210122_gwas_catalog.xlsx`

#### Height

* height: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0004339>
  - **4912 SNPs** from **51 studies**
  
#### BMI

* bmi: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0004340>
  - **7573 SNPs** from **155 studies**
  
#### Educational attainment

* self reported educational attainment: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0004784>
  - **3989 SNPs** from **24 studies**
  
#### Intelligence

* intelligence: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0004337>
  - **2967 SNPs** from **27 studies**
  
#### IBD

* inflammatory bowel disease: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0003767>
  - **536 SNPs** from **34 studies**

#### Pigmentation

* skin pigmentation: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0003784>
  - **102 SNPs** from **6 studies**

* skin pigmentation measurement: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0007009>
  - **233 SNPs** from **9 studies**

* eye color: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0003949>
  - **77 SNPs** from **13 studies**
  
* eye colour measurement:
<https://www.ebi.ac.uk/gwas/efotraits/EFO_0009764>
  - **202 SNPs** from **9 studies**
  
* hair color: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0003924>
  - **424 SNPs** from **18 studies**
  
* hair colour measurement: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0007822>
  - **541 SNPs** from **6 studies**

### Read into list

```{r}
file_in = here::here("data", "20210122_gwas_catalog.xlsx")
# Create vector of traits
traits = c("hei", "bmi", "edu", "int", "ibd", "pig")
names(traits) = traits
# Assign sheets to traits
sheets <- seq(1:11)
names(sheets) <- c("hei", "bmi", "edu", "int", "ibd", rep("pig", 6))

# get sheets
sheet_names <- readxl::excel_sheets(file_in)

# Create function to read in data
read_catalog_data <- function(path, target_sheet){
  # Read in data
  out = readxl::read_xlsx(path, sheet = target_sheet) %>% 
    dplyr::select(CHR = CHR_ID, 
                  POS = CHR_POS, 
                  SNP_AL = `STRONGEST SNP-RISK ALLELE`, 
                  P = `P-VALUE`, 
                  OR_OR_BETA = `OR or BETA`, 
                  MAPPED_TRAIT,
                  STUDY = `STUDY ACCESSION`,
                  SAMPLE = `INITIAL SAMPLE SIZE`) %>% 
    # Split SNP and risk allele into separate columns
    dplyr::mutate(TOP_SNP = stringr::str_split(SNP_AL, "-", simplify = T)[, 1],
                  RISK_ALLELE = stringr::str_split(SNP_AL, "-", simplify = T)[, 2]) %>% 
    # Reorder and select
    dplyr::select(CHR, POS, TOP_SNP, RISK_ALLELE, P, OR_OR_BETA, MAPPED_TRAIT, STUDY, SAMPLE)
  # Change variables to specific types
  out$CHR <- as.integer(out$CHR)
  out$POS <- as.numeric(out$POS)
  out$P <- as.numeric(out$P)
  # return DF
  return(out)
}

# Read in data
counter <- 0
data_list = lapply(traits, function(trait){
  # set counter 
  counter <<- counter + 1
  # set target file
  target_file = file_in
  # get target sheet
  target_sheet = sheets[names(sheets) == trait]
  length(target_sheet)
  # read in pigmentation data from multiple sheets and bind into single DF
  if (length(target_sheet) > 1){
    # loop over each sheet
    df <- lapply(target_sheet, function(sheet){
      out <- read_catalog_data(target_file,
                               target_sheet = sheet)
    })
    # set name of each DF to name of sheet (replacing spaces with underscores)
    names(df) = sheet_names[target_sheet] %>% 
      stringr::str_replace_all(" ", "_")
    # bind DFs into single DF
    df <- dplyr::bind_rows(df, .id = "PIG_PHENO")
  } 
  else {
    # read in other data
    df <- read_catalog_data(target_file,
                            target_sheet = target_sheet)
  }
  # Set PHENO column
  df$PHENO <- factor(trait, levels = trait_levels)
  # Recode PHENO
  df$PHENO = dplyr::recode(df$PHENO, !!!recode_vec)
  # Create list
  out = list()
  # Return DF as "raw"
  out[["raw"]] = df
  
  return(out)
})

# How many SNPs in raw data
lapply(data_list, function(x) nrow(x[["raw"]]))

# Clean data
data_list = lapply(data_list, function(pheno){
  df_clean = pheno[["raw"]]
  # Remove rows with p-value of 0 (only 32 of them, associated with suntan)
  df_clean = df_clean[df_clean$P != 0, ]
  # Remove rows with NA in CHR
  df_clean = df_clean[!is.na(df_clean$CHR), ]
  # Remove duplicates
  ## Find SNPs that are duplicated
  dupes = unique(df_clean$TOP_SNP[duplicated(df_clean$TOP_SNP) | duplicated(df_clean$TOP_SNP, fromLast = T)])
  ## Select only 1 SNP from each set of duplicated SNPs
  dupe_filt = lapply(dupes, function(dupe){
    # Take the one with the lowest P-value
    min_p = min(df_clean$P[df_clean$TOP_SNP == dupe])
    out = df_clean[df_clean$TOP_SNP == dupe & df_clean$P == min_p, ]
    # If there are still duplicates due to having equal P, take the one with the largest effect size
    if (nrow(out) > 1 ){
      out = out[which.max(out$OR_OR_BETA), ]
    }
    return(out)
  })
  # Bind list into DF
  dupe_filt = dplyr::bind_rows(dupe_filt)
  # Extract non-duplicated rows
  non_dupe = df_clean[!duplicated(df_clean$TOP_SNP) & !duplicated(df_clean$TOP_SNP, fromLast = T), ]
  # Bind non-duplicated rows with filtered duplicates
  df_clean = rbind(non_dupe, dupe_filt) 
  # Add to list
  pheno[["clean"]] = df_clean
  
  return(pheno)
})

# New SNP count
lapply(data_list, function(x) nrow(x[["clean"]]))
```

```{r}
lapply(data_list, function(pheno){
  knitr::kable(head(pheno[["clean"]]))
})
```

Get unique mapped traits

```{r}
lapply(data_list, function(pheno){
  unique(pheno$clean$MAPPED_TRAIT)
})
```

Are any of the OR_OR_BETAs negative? 

```{r}
any(unlist(lapply(data_list, function(pheno) {
  any(pheno$clean$OR_OR_BETA < 0,na.rm = T)
})))
```

This must means that the `RISK_ALLELE` always affects the trait positively. 

But for what proportion of SNPs is the `RISK_ALLELE` not stated?

```{r}
lapply(data_list, function(pheno) {
  length(which(pheno$clean$RISK_ALLELE == "?")) / nrow(pheno$clean)
})
```

[**NOTE**]{colour = "red"}: In cases where `RISK_ALLELE` isn't provided, treat the `ALT` allele as `RISK_ALLELE`.

### Generate Manhattan plots

Plot

```{r}
counter = 0
lapply(data_list, function(pheno_df){
  # set counter
  counter <<- counter + 1
  df = pheno_df[["clean"]]
  trait = unique(df$PHENO)
  # Get title
  title <- paste(trait, "\n", "SNP count:", nrow(df))
  # Plot
  get_man(df, trait = trait, title = title, chr = "CHR", bp = "POS", snp = "TOP_SNP", p = "P")
})
```

Save

```{r, eval = F}
output_dir = here::here("plots", "20210122_manhattan_all_snps")

counter = 0
lapply(data_list, function(pheno_df){

  # set counter
  counter <<- counter + 1
  df = pheno_df[["clean"]]
  trait = unique(df$PHENO)
  # Get title
  title <- paste(trait, "\n", "SNP count:", nrow(df))
  # Set file name to save
  file = file.path(output_dir,
                   paste("manhattan_",
                         names(data_list)[counter],
                         ".svg",
                         sep = ""))
  # Set up graphics device
  svg(file,
      width = 10,
      height = 6)  
  
  # Plot
  get_man(df, trait = trait, chr = "CHR", bp = "POS", snp = "TOP_SNP", p = "P")
  
  dev.off()
})
```

#### Create list of target SNPs to extract from 1KG

```{r, eval = F, warning = F, results = "hide"}

dest_dir = here::here("data", "20210122_snp_hit_lists")

# Make directory
dir.create(dest_dir)
  
# Just SNPs for extracting from 1KG
counter <- 0
lapply(data_list, function(pheno){
  df = pheno[["clean"]]
  # Set counter
  counter <<- counter + 1
  # Set file basename
  trait = names(data_list)[counter]
  filename = paste(trait, ".list", sep = "")
  # Write SNPs to file
  readr::write_lines(df$TOP_SNP, file.path(dest_dir, filename))
})

# SNPs and P-values with header for clumping with Plink
counter <- 0
lapply(data_list, function(pheno){
  df = pheno[["clean"]]
  # Set counter
  counter <<- counter + 1
  # Set file basename
  trait = names(data_list)[counter]
  filename = paste(trait, "_with_P.txt", sep = "")
  # Write SNPs to file
  df %>% 
    dplyr::select(SNP = TOP_SNP, P) %>% 
    readr::write_tsv(file.path(dest_dir, filename))
})
```

## Filter 1KG VCF for target SNPs

```{r, engine='bash', eval = F}

traits=$(echo hei bmi edu int ibd pig)
ref=../refs/hs37d5.fa.gz
in_vcf=../vcfs/1gk_all.vcf.gz
snps_dir=data/20210122_snp_hit_lists
out_dir=data/20210125_snp_hits_filtered

mkdir -p $out_dir

for trait in $(echo $traits ); do
  bsub \
    -M 10000 \
    -o ../log/20210122_extract_snps_$trait.out \
    -e ../log/20210122_extract_snps_$trait.err \
    """
    conda activate fst_env_rhel ;
    gatk SelectVariants \
      -R $ref \
      -V $in_vcf \
      --keep-ids $snps_dir/$trait.list \
      -O $out_dir/$trait.vcf.gz 
    """ ;
done
```

## Get allele frequencies of SNP hits with `Plink2`

### Import 1GK metadata (for sample-population key)

Downloded via this page: <http://www.internationalgenome.org/data>
Download link: <http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/working/20130606_sample_info/20130606_sample_info.xlsx>. 

Saved here: `data/20130606_sample_info.xlsx`

```{r, warning=FALSE, results = 'asis'}
samples_file = here::here("data", "20130606_sample_info.xlsx")

meta = readxl::read_xlsx(samples_file,
                         sheet = "Sample Info") %>%
  dplyr::select(Sample, Population, Gender)

knitr::kable(head(meta))
```

### Write population file for Plink2

```{r, eval = F}
sample_popn_key_file = here::here("data", "plink2_sample_popn_key.txt")

write.table(meta[, 1:2],
            sample_popn_key_file,
            quote = F,
            sep = "\t",
            row.names = F,
            col.names = F)
```

### Run `Plink2` for SNP hits

(Take only biallelic SNPs.)

```{r, engine='bash', eval = F}

conda activate fst_env_rhel

# Set variables

traits=$(echo hei bmi edu int ibd pig)
in_vcf_dir=data/20210125_snp_hits_filtered
popn_file=data/plink2_sample_popn_key.txt
out_dir=data/20210122_snp_hits_alfreqs

# Set up directories
mkdir -p $out_dir

for trait in $(echo $traits); do
  mkdir -p $out_dir/$trait; 
done   

# Run Plink2

## Get global AF
for trait in $(echo $traits); do
  plink2 \
    --vcf $in_vcf_dir/$trait.vcf.gz \
    --freq \
    --max-alleles 2 \
    --snps-only \
    --out $out_dir/$trait/$trait.all
done

## Get AF per population
for trait in $(echo $traits); do
  plink2 \
    --vcf $in_vcf_dir/$trait.vcf.gz \
    --freq \
    --max-alleles 2 \
    --snps-only \
    --pheno iid-only $popn_file \
    --loop-cats PHENO1 \
    --out $out_dir/$trait/$trait ;
done
```

### Add allele frequency files

```{r}
target_dir = here::here("data", "20210122_snp_hits_alfreqs")

# Global
counter <- 0
data_list = lapply(data_list, function(pheno){
  # set counter 
  counter <<- counter + 1
  # get trait name
  trait = names(data_list)[counter]
  # get file path
  target_path = file.path(target_dir, trait, paste(trait, ".all.afreq", sep = ""))
  # read in data
  clean_af = read_afreq(target_path)
  # add POPN column
  clean_af$POPN = "all"
  # add to list
  pheno[["clean_af"]] = clean_af
  
  return(pheno)
})

# Per population
counter <- 0
data_list = lapply(data_list, function(pheno){
  # set counter
  counter <<- counter + 1
  # get trait name
  trait = names(data_list)[counter]
  # get file path
  target_files = list.files(file.path(target_dir, trait),
                            pattern = ".*[^all]\\.afreq",
                            full.names = T)
  # get popn names
  names(target_files) = basename(target_files) %>% 
    str_split("\\.", simplify = T) %>% 
    subset(select = 2)
  # read files and bind into single DF
  popn_afreqs = lapply(target_files, function(popn){
    df = read_afreq(popn)
  }) %>% 
    dplyr::bind_rows(.id = "POPN")# %>% 
#    dplyr::select(-OBS_CT) %>% 
#    tidyr::pivot_wider(id_cols = SNP, names_from = POPN, values_from = ALT_FREQS)
  # combine with `clean_af`
  pheno[["clean_af"]] = dplyr::bind_rows(pheno[["clean_af"]],
                                         popn_afreqs)
  
  return(pheno)
})
```

<!--
### Convert to MAJ/MIN alleles to get MAF

```{r}
data_list = lapply(data_list, function(pheno){
  df = pheno[["clean_af"]]
  # convert to MAF
  df = df %>% 
    dplyr::mutate(MAJ = if_else(ALT_FREQS <= 0.5,
                                REF,
                                ALT),
                  MIN = ifelse(ALT_FREQS <= 0.5,
                               ALT,
                               REF),
                  MAF = ifelse(ALT_FREQS <= 0.5,
                               ALT_FREQS,
                               1 - ALT_FREQS))
  pheno[["clean_af"]] = df
  
  return(pheno)
})
```

### Histograms of the global MAF distributions (i.e. all 26 populations together)

```{r}
# Extract clean_af DFs
alfreq_list_glob = lapply(data_list, function(pheno) pheno[["clean_af"]])

# Merge into single Df
alfreq_glob_df = dplyr::bind_rows(alfreq_list_glob, .id = "trait")

# Make `trait` a factor
alfreq_glob_df$trait = factor(alfreq_glob_df$trait, levels = trait_levels)
# Recode traits for plotting
alfreq_glob_df$trait = dplyr::recode(alfreq_glob_df$trait, !!!recode_vec)
```

Plot
```{r, fig.height=4, fig.width=6.5}
alfreq_glob_df %>% 
  ggplot(aes(MAF, fill = trait)) +
    geom_histogram(bins = 50) +
    scale_fill_manual(values = pal_primary) +
    facet_wrap(~trait, nrow = 2) +
    guides(fill = F) +
    theme_bw() +
    ggtitle("MAF distributions (all 1KG populations combined)")
```

```{r, eval = F}
# Save
ggsave(here("plots", "20210114_global_maf_distributions.svg"),
       device = "svg",
       units = "cm",
       dpi = 400,
       height = 12,
       width = 19.5)
```

-->

## Set up negative controls

Pull out random SNPs with the same global allele frequencies as the GWAS SNP-hits

### Bin SNP hits by allele frequency

Bind to clean DF to get AFs of risk allele

[**NOTE**]{colour = "red"}: If `RISK_ALLELE` is unknown, set the allele frequency to `ALT_FREQS`

```{r}
data_list = lapply(data_list, function(pheno){
  # join DFs
  df = dplyr::left_join(pheno[["clean"]],
                        dplyr::select(pheno[["clean_af"]],
                                      -CHR),
                        by = c("TOP_SNP" = "SNP"))
  # get AF of risk allele
  df$RISK_AF = dplyr::if_else(df$RISK_ALLELE == "?",
                              df$ALT_FREQS,
                              dplyr::if_else(df$RISK_ALLELE == df$ALT,
                                             df$ALT_FREQS,
                                             1 - df$ALT_FREQS))
  # add `HIT_CONTROL` column
  df$HIT_CONTROL = "hit"
  # add to list
  pheno[["consol"]] = df
  
  return(pheno)
})
```

<!--
Plot RISK_AF against OR_OR_BETA

```{r}
af_plot = lapply(data_list, function(pheno) pheno[["consol"]])
af_plot  = dplyr::bind_rows(af_plot) %>% 
  dplyr::filter(POPN == "all")
```

```{r}
af_plot %>% 
  ggplot() +
    geom_point(aes(RISK_AF, OR_OR_BETA, colour = PHENO)) +
    scale_colour_manual(values = pal_primary) +
    facet_wrap(~PHENO, nrow = 2) +
    guides(colour = F, alpha = F) +
    theme_bw() +
    ggtitle("Risk allele frequency vs effect size (OR or beta)")

# Zoom in
af_plot %>% 
  ggplot() +
    geom_point(aes(RISK_AF, OR_OR_BETA,
                   colour = PHENO,
                   alpha = 0.1)) +
    scale_colour_manual(values = pal_primary) +
    facet_wrap(~PHENO, nrow = 2) +
    guides(colour = F, alpha = F) +
    theme_bw() +
    ggtitle("Risk allele frequency vs effect size (OR or beta)") +
    ylim(0,20)
```
Looks strange.

-->

Bin by risk allele frequency

```{r}
# 1% intervals
breakpoints = seq(0, 1, 0.01)

data_list = lapply(data_list, function(pheno){
  # choose DF
  df = pheno[["consol"]]
  # add bins
  df$BIN_100 = cut(df$RISK_AF, breaks = breakpoints, labels = F)
  # save back into list
  pheno[["consol"]] = df
  
  return(pheno)
})

```

Extract key columns and write to file

```{r, eval = F, message=F}
out_dir = here::here("data", "20210126_snp_risk_hits_binned")

dir.create(out_dir)

# Save list
counter <- 0
risk_afs = lapply(data_list, function(pheno){
  # set counter 
  counter <<- counter + 1
  # get target DF
  df = pheno[["consol"]]
  # filter
  df = df %>% 
    dplyr::filter(POPN == "all") %>% # take only global AFs 
    dplyr::select(TOP_SNP, BIN_100) %>% 
    tidyr::drop_na() # drop NAs
  # set output path
  trait = names(data_list)[counter]
  path_out = file.path(out_dir, paste(trait, ".txt", sep = ""))
  # write to file
  readr::write_tsv(df, path_out)
})


```

### Bin 1KG SNPs 

#### Get allele frequencies from 1KG

With `Plink2`, per chromosome for speed.

```{r, engine='bash', eval=F}
# set output directory
in_file=../vcfs/1gk_all.vcf.gz
out_dir=../big_data/20210125_alfreqs_all

mkdir -p $out_dir

# Per chromosome
for chr in $(seq 1 22) ; do
  # create allele-freq tables
  bsub \
    -M 10000 \
    -o ../log/20210125_plink_alfreq_$chr.out \
    -e ../log/20210125_plink_alfreq_$chr.err \
    """
    conda activate fst_env_rhel ;
    plink2 \
      --vcf $in_file \
      --freq \
      --chr $chr \
      --max-alleles 2 \
      --snps-only \
      --out $out_dir/$chr ";
done 
```

#### Bin them and save to single file

```{r, eval = F}
# On cluster

library(here)
source(here::here("code", "scripts", "source.R"))

# Set variables
in_dir = "../big_data/20210125_alfreqs_all"
out_dir = "../big_data/20210125_alfreqs_all_binned"
breakpoints = seq(0, 1, 0.01) # 1% bins

# Create output directory
dir.create(out_dir)

# Get list of input files
in_files = list.files(in_dir, pattern = ".afreq", full.names = T)

# Read in files, add bins, and write to output
freq_list = lapply(in_files, function(chr_file){
  # read in file
  df = read_afreq(chr_file)
  # add bins
  df$BIN_100 = cut(df$ALT_FREQS, breaks = breakpoints, labels = F)
  # write file
  readr::write_tsv(df, file = file.path(out_dir, basename(chr_file)))
})

# Combine into single DF
freq_df = dplyr::bind_rows(freq_list)

# Write to file
readr::write_tsv(freq_df, file = file.path(out_dir, "all.afreq"))
```

#### Pull out random SNPs with same AF as trait risk alleles

```{r, eval = F}
# On cluster

library(here)
source(here::here("code", "scripts", "source.R"))

# Variables
target_snp_df = here::here("data", "20210125_risk_afs.txt")
input_risk_snp_dir = here::here("data", "20210126_snp_risk_hits_binned")
all_1kg_bins = "../big_data/20210125_alfreqs_all_binned/all.afreq"
initial_seed = 123
output_file = here::here("data", "20210125_risk_afs_with_random_snps.txt")
#random_snp_list_out = here::here("data", "20210125_random_snps.list")
output_dir = here::here("data", "20210126_random_snps")

dir.create(output_dir)

## Read in target SNP DF and split into list by bin
risk_list = readr::read_tsv(target_snp_df,
                            col_names = T) %>% 
  split(., f = .$BIN_100)

## Read in 1KG data
freq_df = readr::read_tsv(all_1kg_bins)

# For each bin in `risk_list`, pull out the same number of random number 1KG SNPs with the same bin

## Set seed
set.seed(initial_seed)

## Get seeds for each bin
seeds = sample(1:1000, length(risk_list))

## Run over list
counter <- 0
out = lapply(risk_list, function(bin_df){
  # set counter 
  counter <<- counter + 1
  # get target bin
  target_bin = as.integer(names(risk_list)[counter])
  # set seed
  set.seed(seeds[counter])
  # get number of matches required
  hits_n = nrow(bin_df)
  # filter 1kg DF for SNPs with same bin and get random hits
  random_hits = freq_df %>% 
    #dplyr::select(SNP, ALT_FREQS, OBS_CT, BIN_100) %>% 
    dplyr::filter(BIN_100 == target_bin) %>% 
    dplyr::slice_sample(n = hits_n) %>% 
    dplyr::rename(RANDOM_SNP = SNP,
                  RANDOM_BIN_100 = BIN_100)
  # bind `random_hits` to target SNP df
  df_out = cbind(bin_df, random_hits)
  
  # Save to file
  readr::write_tsv(df_out, output_file)
  return(df_out)
}) %>% 
  # bind into single data frame
  dplyr::bind_rows()


# Save list of SNPs for each pheno
new_list = out
new_list$PHENO = dplyr::recode(out$PHENO, !!!rev_recode_vec)
new_list$PHENO = factor(new_list$PHENO, levels = trait_levels)
new_list = split(new_list, f = new_list$PHENO)
counter <- 0
lapply(new_list, function(pheno){
  counter <<- counter + 1
  trait = names(new_list)[counter]
  out_path = file.path(output_dir, paste(trait, ".list", sep = ""))
  readr::write_lines(pheno$RANDOM_SNP, out_path)
})

# Save just SNPs to file (for Plink to get per-population AFs)
random_snps = out$RANDOM_SNP

readr::write_lines(random_snps, random_snp_list_out)
```

#### Filter VCFs for random SNPs

```{bash, eval = F}
traits=$(echo hei bmi edu int ibd pig)
ref=../refs/hs37d5.fa.gz
in_vcf=../vcfs/1gk_all.vcf.gz
snps_dir=data/20210126_random_snps
out_dir=data/20210126_snp_rndm_filtered

mkdir -p $out_dir

for trait in $(echo $traits ); do
  bsub \
    -M 10000 \
    -o ../log/20210126_extract_snps_$trait.out \
    -e ../log/20210126_extract_snps_$trait.err \
    """
    conda activate fst_env_rhel ;
    gatk SelectVariants \
      -R $ref \
      -V $in_vcf \
      --keep-ids $snps_dir/$trait.list \
      -O $out_dir/$trait.vcf.gz 
    """ ;
done
```

#### Get per-population allele frequencies of random SNPs 

```{bash, eval = F}

conda activate fst_env_rhel 

random_snps_list=data/20210125_random_snps.list
in_vcf=../vcfs/1gk_all.vcf.gz
popn_key=data/plink2_sample_popn_key.txt
out_dir=data/20210125_random_snps_alfreqs/
mkdir -p $out_dir
out=$out_dir/random

plink2 \
  --vcf $in_vcf \
  --extract $random_snps_list \
  --freq \
  --pheno iid-only $popn_key \
  --loop-cats PHENO1 \
  --out $out
```

#### Bind into single DF

```{r, message = F}
in_file_random = here::here("data", "20210125_risk_afs_with_random_snps.txt")
in_dir_afreq = here::here("data", "20210125_random_snps_alfreqs")

# Read in data

## Random SNPs
random_snps = readr::read_tsv(in_file_random)
# add `POPN` column
random_snps$POPN = "all"

## Popn afreqs
target_files = list.files(in_dir_afreq, pattern = ".afreq", full.names = T)

names(target_files) = basename(target_files) %>% 
  str_split("\\.", simplify = T) %>% 
  subset(select = 2)

popn_afreqs = lapply(target_files, function(popn){
  df = read_afreq(popn)
}) %>% 
  dplyr::bind_rows(.id = "POPN") # %>% 
#  dplyr::select(-OBS_CT) %>% 
#  tidyr::pivot_wider(id_cols = SNP, names_from = POPN, values_from = c(ALT_FREQS, OBS_CT))

# Bind `popn_afreqs` to `random_snps`
random_afreqs = dplyr::full_join(dplyr::select(random_snps, -c(POPN, ALT_FREQS, OBS_CT)),
                                 popn_afreqs,
                                 by = c("RANDOM_SNP" = "SNP", "REF", "ALT", "CHR"))
# Bind `all` AFs
random_afreqs = rbind(random_afreqs, random_snps)

## Recode PHENO
random_afreqs$PHENO = dplyr::recode(random_afreqs$PHENO, !!!rev_recode_vec)

## Add `HIT_CONTROL` column
random_afreqs$HIT_CONTROL = "control"
```

#### Add to `data_list`

```{r}
counter <- 0
data_list = lapply(data_list, function(pheno){
  # set counter
  counter <<- counter + 1
  # set target pheno
  target_pheno = names(data_list)[counter]
  # add random afreqs
  random_af = random_afreqs %>% 
    dplyr::filter(PHENO == target_pheno)
  # recode PHENO
  random_af$PHENO = dplyr::recode(random_af$PHENO, !!!recode_vec)
  # add to list
  pheno[["random_af"]] = random_af
  
  return(pheno)
})
```

## Clump to get lead SNPs

Use `Plink1.9` (`Plink2.0` doesn't have a `clump` function.)

From the `Plink1.7` documentation (<http://zzz.bwh.harvard.edu/plink/clump.shtml>), which applies to `Plink1.9`:

> The clumping procedure takes all SNPs that are significant at threshold p1 that have not already been clumped (denoting these as index SNPs) and forms clumps of all other SNPs that are within a certain kb distance from the index SNP (default 250kb) and that are in linkage disequilibrium with the index SNP, based on an r-squared threshold (default 0.50)... This is a greedy algorithm and so each SNP will only appear in a single clump, if at all. 

> ...[t]he TOTAL field lists all SNPs that are clumped with the index SNP, irrespective of the p-value for those SNPs. This number is then split into those clumped SNPs that are not significant (p>0.05) and various other groups defined by significance thresholds. For SNPs that are significant at the p2 threshold, they are listed explicitly. The (1) after each SNP name refers to the results file they came from (in this case, there is only a single result file specified, so all values are 1).

Here, we're taking all SNPs with *P* < 1e-08 as index SNPs, and it will explicitly list all SNPs within the clump that also meet that threshold. 

```{bash, eval = F}

# Activate environment
conda activate fst_env_rhel

# Set variables
traits=$(echo hei bmi edu int ibd pig)
in_vcf_dir=data/20210125_snp_hits_filtered
snp_p_dir=data/20210122_snp_hit_lists
out_dir=data/20210125_clumped

r2_params=$(echo 0.1 0.2 0.3)
kb_params=$(echo 500 750 1000 )

# Make directory
mkdir -p $out_dir

# Run with different parameters
for trait in $(echo $traits ); do

  mkdir -p $out_dir/$trait ;
  
  for r2 in $r2_params ; do
    for kb in $kb_params ; do
      bsub \
        -o ../log/20210125_clump_$trait\_$r2\_$kb.out \
        -e ../log/20210125_clump_$trait\_$r2\_$kb.err \
        """
        conda activate fst_env_rhel ;
        plink \
          --vcf $in_vcf_dir/$trait.vcf.gz \
          --clump $snp_p_dir/$trait\_with_P.txt \
          --clump-p1 0.00000001 \
          --clump-p2 0.00000001 \
          --clump-r2 $r2 \
          --clump-kb $kb \
          --out $out_dir/$trait/r2-$r2\_kb-$kb 
        """  ;
    done ;
  done;  
done

```

### Add clumped SNP files to `data_list`

```{r}
target_dir = here::here("data", "20210125_clumped")


counter <- 0
data_list = lapply(data_list, function(pheno){
  # set counter
  counter <<- counter + 1
  # get trait name
  trait = names(data_list)[counter]
  # get file path
  target_files = list.files(file.path(target_dir, trait),
                            pattern = ".clumped",
                            full.names = T)
  names(target_files) = gsub(".clumped", "", basename(target_files))
  # read files as `clumped`
  counter_clump <- 0
  clumped = lapply(target_files, function(params){
    # set counter
    counter_clump <<- counter_clump + 1
    # split params string
    param_str = names(target_files)[counter_clump] %>% 
      stringr::str_split("_", simplify = T) %>%
      stringr::str_split("-", simplify = T)
    # get params
    r2 = as.numeric(param_str[1,2])
    kb = as.integer(param_str[2,2])
    # read files
    df = read.table(params, header = T)
    # add params to DF
    df$r2 = r2
    df$kb = kb
    
    return(df)
  })
  # add `clumped` list to `data_list`
  pheno[["clumped"]] = clumped
  # bind `clumped` into single DF and add to `data_list`
  pheno[["clumped_all"]] = dplyr::bind_rows(clumped)
  
  return(pheno)
})
```

<!--
## Compare allele frequencies

### Read in data

```{r}
target_dirs <- list.dirs(here::here("data", "20200622_plink2_alfreqs"), recursive = F)

al_freq_lst <- lapply(target_dirs, function(x){
  target_files <- list.files(x, pattern = ".afreq", full.names = T)
  # read in data
  data_lst <- lapply(target_files, function(target_file){
    read.table(target_file,
               header = T,
               comment.char = "")
  })
  # fix names of populations
  names(data_lst) <- gsub(pattern = "edu.|hei.|bmi.|ibd.|pig.|.afreq",
                          replacement = "",
                          x = list.files(x, pattern = ".afreq"))
  return(data_lst)
})

# set names
names(al_freq_lst) <- basename(target_dirs)

# reorder for (1) height, (2) eduyears, (3) ibd, (4) pigmentation
al_freq_lst <- al_freq_lst[c(2, 1, 3, 4)]
```

### Turn into single table for each pheno

```{r}
al_freq_df <- lapply(al_freq_lst, function(pheno){
  out <- dplyr::bind_rows(pheno, .id = "population") %>% 
    tidyr::pivot_wider(id_cols = c(X.CHROM, ID, REF, ALT),
                       names_from = population,
                       values_from = ALT_FREQS)
})
```

### Randomly swap minor allele

```{r}
set.seed(65)
rdm_sds <- sample(1:100, 4)

counter <- 0
al_freq_df_shuff <- lapply(al_freq_df, function(pheno){
  counter <<- counter + 1
  # set seed
  set.seed(rdm_sds[counter])
  # select SNPs to swap (half of total)
  tgt_indcs <- sample(nrow(pheno), nrow(pheno) /2)
  # swap minor alleles
  pheno[tgt_indcs, 5:ncol(pheno)] <- 1 - pheno[tgt_indcs, 5:ncol(pheno)]
  # return pheno
  return(pheno)
})
```

-->

## Consolidate key data into single DF for analysis

```{r}
clump_param = "r2-0.1_kb-1000"

data_list = lapply(data_list, function(pheno){
  # Filter `consol` by the index SNPs in target `clump`
  target_clump = pheno[["clumped"]][[clump_param]]
  
  final = pheno[["consol"]] %>% 
    dplyr::rename(SNP = TOP_SNP) %>% 
    dplyr::filter(SNP %in% target_clump$SNP) 
  
  # Add allele frequencies of SNP hits (global and per-population)
  
  # Add controls
  controls = pheno[["random_af"]] %>%
    # filter for SNPs in target_clump
    dplyr::filter(TOP_SNP %in% target_clump$SNP) %>% 
    dplyr::select(-c(TOP_SNP, BIN_100, RANDOM_BIN_100), 
                  SNP = RANDOM_SNP) %>% 
    dplyr::mutate(RISK_AF = ALT_FREQS)
  
  final = dplyr::bind_rows(final, controls)  
  pheno[["final"]] = final
  
  return(pheno)
})

# Create final df
final_df = lapply(data_list, function(pheno){
  out = pheno[["final"]]
  
  return(out)
}) %>% 
  dplyr::bind_rows()

# Set factors
final_df$PHENO <- factor(final_df$PHENO, levels = trait_levels_verb)
final_df$HIT_CONTROL = factor(final_df$HIT_CONTROL, levels = hit_control_levels)

# Create DF for plotting
final_plt = final_df %>% 
  dplyr::select(SNP, PHENO, POPN, RISK_AF, HIT_CONTROL) %>% 
  tidyr::pivot_wider(names_from = POPN, values_from = RISK_AF) 

```

# Analysis

## Manhattan plots

```{r, message = F}
counter = 0
lapply(unique(final_df$PHENO), function(pheno){
  # set counter
  counter <<- counter + 1
  df = final_df %>% 
    dplyr::filter(PHENO == pheno & HIT_CONTROL == "hit")
  # Get number of SNPs
  snp_n = length(unique(df$SNP))
  # Get title
  title <- paste(pheno, "\n", "SNP count:", snp_n)
  # Plot
  get_man(df, trait = pheno, title = title, chr = "CHR", bp = "POS", snp = "SNP", p = "P")
})
```

## Allele frequency distributions of risk alleles

```{r}
final_df %>%
  dplyr::filter(HIT_CONTROL == "hit") %>% 
  ggplot(aes(RISK_AF, fill = PHENO)) +
    geom_histogram(bins = 100) +
    scale_fill_manual(values = pal_primary) +
    facet_wrap(vars(PHENO), nrow = 2) +
    guides(fill = F) +
    xlab("Risk allele frequency") +
    ylab("Count") +
    theme_bw() +
    ggtitle("Frequency distribution of \"risk\" alleles (all 1KG populations combined)")
```
## Allele frequency vs effect size

```{r}
final_df %>% 
  dplyr::filter(HIT_CONTROL == "hit" & POPN == "all") %>% 
  ggplot() +
    geom_point(aes(RISK_AF, OR_OR_BETA, colour = PHENO),
               alpha = 0.2) +
    scale_colour_manual(values = pal_primary) +
    facet_wrap(vars(PHENO), nrow = 2) +
    guides(colour = F, alpha = F) +
    theme_bw() +
    ggtitle("Risk allele frequency vs effect size (OR or beta)")

# Zoom in
final_df %>% 
  dplyr::filter(HIT_CONTROL == "hit" & POPN == "all") %>% 
  ggplot() +
    geom_point(aes(RISK_AF, OR_OR_BETA, colour = PHENO),
               alpha = 0.2) +
    scale_colour_manual(values = pal_primary) +
    facet_wrap(vars(PHENO), nrow = 2) +
    guides(colour = F, alpha = F) +
    theme_bw() +
    ggtitle("Risk allele frequency vs effect size (OR or beta)") +
    ylim(0,20)
```

## Allele frequencies comparing CEU, CHS, and YRI

### 2D

#### CEU vs CHS

```{r}
target_popns = c("CEU", "CHS")

final_plt %>% 
  ggplot() +
    geom_point(aes_string(target_popns[1], target_popns[2], colour = "PHENO"),
               alpha = 0.3, size = 2) + 
    scale_colour_manual(values = pal_primary) +
    facet_wrap(vars(PHENO, HIT_CONTROL)) +
    guides(colour = F, alpha = F) +
    theme_bw() +
    ggtitle(paste(target_popns[1], "vs", target_popns[2], sep = " "))
```

#### CEU vs YRI

```{r}
target_popns = c("CEU", "YRI")

final_plt %>% 
  ggplot() +
    geom_point(aes_string(target_popns[1], target_popns[2], colour = "PHENO"),
               alpha = 0.3, size = 2) + 
    scale_colour_manual(values = pal_primary) +
    facet_wrap(vars(PHENO, HIT_CONTROL)) +
    guides(colour = F, alpha = F) +
    theme_bw() +
    ggtitle(paste(target_popns[1], "vs", target_popns[2], sep = " "))
```

#### CHS vs YRI

```{r}
target_popns = c("CHS", "YRI")

final_plt %>% 
  ggplot() +
    geom_point(aes_string(target_popns[1], target_popns[2], colour = "PHENO"),
               alpha = 0.3, size = 2) + 
    scale_colour_manual(values = pal_primary) +
    facet_wrap(vars(PHENO, HIT_CONTROL)) +
    guides(colour = F, alpha = F) +
    theme_bw() +
    ggtitle(paste(target_popns[1], "vs", target_popns[2], sep = " "))
```


<!--

### Read in population frequency data

```{r}
target_dirs <- list.dirs(here::here("data", "20200622_plink2_alfreqs"), recursive = F)

al_freq_lst <- lapply(target_dirs, function(x){
  target_files <- list.files(x, pattern = ".afreq", full.names = T)
  # read in data
  data_lst <- lapply(target_files, function(target_file){
    read.table(target_file,
               header = T,
               comment.char = "")
  })
  # fix names of populations
  names(data_lst) <- gsub(pattern = "edu.|hei.|bmi.|ibd.|pig.|.afreq",
                          replacement = "",
                          x = list.files(x, pattern = ".afreq"))
  return(data_lst)
})

# set names
names(al_freq_lst) <- basename(target_dirs)
```

### Turn into single table for each pheno

```{r}
al_freq_df <- lapply(al_freq_lst, function(pheno){
  out <- dplyr::bind_rows(pheno, .id = "population") %>% 
    tidyr::pivot_wider(id_cols = c(X.CHROM, ID, REF, ALT),
                       names_from = population,
                       values_from = ALT_FREQS)
})
```

### Randomly swap minor allele

```{r}
set.seed(65)
rdm_sds <- sample(1:100, 5)

counter <- 0
al_freq_df_shuff <- lapply(al_freq_df, function(pheno_df){
  counter <<- counter + 1
  # set seed
  set.seed(rdm_sds[counter])
  # select SNPs to swap (half of total)
  tgt_indcs <- sample(nrow(pheno_df), nrow(pheno_df) /2)
  # swap minor alleles
  pheno_df[tgt_indcs, 5:ncol(pheno_df)] <- 1 - pheno_df[tgt_indcs, 5:ncol(pheno_df)]
  # return pheno_df
  return(pheno_df)
})
```

### Bind in to single data frame and save

```{r}
final = dplyr::bind_rows(al_freq_df_shuff, .id = "phenotype")
```

```{r, eval = F}
final %>% 
  readr::write_tsv(here("data", "20210114_pheno_alfreqs.txt.gz"))
```


### Plot

```{r}
# Set up titles vector
titles <- c("Height", "Educational Attainment", "Inflammatory Bowel Disease", "Pigmentation")
```

#### 2D

##### YRI v CHS

```{r, message=F, warning=F}
counter <- 0
lapply(al_freq_df_shuff, function(pheno){
  counter <<- counter + 1
  ggplot(pheno,
         aes(YRI, CHS)) +
    geom_point(size = 0.5) +
    coord_fixed() +
    geom_smooth(se = F, colour = "red") +
    geom_abline(intercept = 0, slope = 1, colour = "blue") +
    xlab("Allele frequency in YRI") +
    ylab("Allele frequency in CHS") +
    labs(title = titles[counter])
})
```

##### YRI v CEU

```{r, message=F, warning=F}
counter <- 0
lapply(al_freq_df_shuff, function(pheno){
  counter <<- counter + 1
  ggplot(pheno,
         aes(YRI, CEU)) +
    geom_point(size = 0.5) +
    coord_fixed() +
    geom_smooth(se = F, colour = "red") +
    geom_abline(intercept = 0, slope = 1, colour = "blue") +
    xlab("Allele frequency in YRI") +
    ylab("Allele frequency in CEU") +
    labs(title = titles[counter])
})
```

-->

#### 3D

```{r, message=F, warning=F}
colourscales <- c("Viridis", "Hot", "Bluered", "Electric")
titles <- c("Height", "Educational Attainment", "IBD", "Skin/hair pigmentation")

counter <- 0
plts <- lapply(al_freq_df_shuff, function(pheno){
  counter <<- counter + 1
  # set graph resolution
  graph_reso <- 0.05
  # get lm for data
  loess_model <- loess(CEU ~ 0 + CHS + YRI, data = pheno)
  # set up axes
  axis_x <- seq(min(pheno$CHS), max(pheno$CHS), by = graph_reso)
  axis_y <- seq(min(pheno$YRI), max(pheno$YRI), by = graph_reso)
  # sample points
  lm_surface <- expand.grid(CHS = axis_x,
                            YRI = axis_y,
                            KEEP.OUT.ATTRS = F)
  lm_surface$CEU <- predict(loess_model, newdata = lm_surface)
  lm_surface <- reshape2::acast(lm_surface, YRI ~ CHS, value.var = "CEU")
  # create plot
  plt <- plot_ly(pheno,
                 x = ~CHS,
                 y = ~YRI,
                 z = ~CEU,
                 type = "scatter3d",
                 mode = "markers",
                 marker = list(size = 2),
                 text = pheno$ID) 
  plt <- add_trace(plt,
                   z = lm_surface,
              x = axis_x,
              y = axis_y,
              type = "surface",
              colorscale = colourscales[counter]) %>% 
    layout(title = titles[counter])
  return(plt)
})

plts$hei
plts$edu
plts$ibd
plts$pig
```

## Fst

### Find target VCFs

```{r}
# list target VCFs
target_vcfs <- list.files(here::here("data", "20210125_snp_hits_filtered"),
                          pattern = glob2rx("*.gz"), 
                          full.names = T)

```

### With all populations

#### Get Fst stats for top SNPs

```{r, message=F, warning=F, results=F}
# Create raw list of variants
target_dir = here::here("data", "20210125_snp_hits_filtered")

vcf_list_raw <- lapply(trait_levels, function(trait){
  target_file = file.path(target_dir, paste(trait, ".vcf.gz", sep = ""))
  # read in file
  vcf_out <- pegas::read.vcf(target_file)
  # filter for clumped SNPs
  ## get target SNP IDs
  target_snps = data_list[[trait]]$clumped[[clump_param]]$SNP
  ## filter VCF
  vcf_out = vcf_out[, colnames(vcf_out) %in% target_snps]
  
  return(vcf_out)
})

# Create vector of populations
populations <- unlist(lapply(rownames(vcf_list_raw[[1]]), function(sample){
  meta$Population[meta$Sample == sample]
}))

# Generate Fst stats
fst_out_lst <- lapply(vcf_list_raw, function(pheno){
  out = as.data.frame(pegas::Fst(pheno, pop = populations))
  # put rownames into separate column
  out$snp <- rownames(out)
  
  return(out)
}) %>% 
  # bind into single DF
  dplyr::bind_rows(fst_out_lst, .id = "phenotype")

# make rownames into separate column
fst_out_lst <- lapply(fst_out_lst, function(pheno){
  pheno$
  return(pheno)
})



# Recode phenotype
fst_out_df$phenotype <- factor(fst_out_df$phenotype, levels = trait_levels)
fst_out_df$phenotype = dplyr::recode(fst_out_df$phenotype, !!!recode_vec)

knitr::kable(head(fst_out_df))
```
#### *Fst* histograms

```{r}
fst_out_df %>% 
  ggplot() +
    geom_histogram(aes(Fst, fill = phenotype), bins = 100) +
    facet_wrap(~phenotype) +
    theme_bw() +
    scale_fill_manual(values = pal_primary)
```


#### *Fst* density

##### 2D

```{r, warning= F}
ggplot(fst_out_df, aes(Fst, fill = phenotype)) +
  geom_density() +
  labs(fill = "Phenotype") +
  facet_wrap(~phenotype) +
  ylab("Density") +
  theme_bw() +
  scale_fill_manual(values = pal_primary)
```

##### 3D

```{r, warning = F, message = F}
fst_out_df %>% 
  ggplot() +
    geom_density_ridges2(mapping = aes(x = Fst, y = phenotype, fill = phenotype),
                         scale = 2) +
    scale_fill_manual(values = pal_primary) +
    ylab(label = NULL) +
    theme_bw() +
    guides(fill = guide_legend(reverse=T, 
                               title = "Phenotype")) +
    scale_y_discrete(expand = expand_scale(add = c(0.2, 2.3)))
```

#### Run Kolmogorov-Smirnov Tests

```{r, warning = F}
test = lapply(trait_levels_verb, function(trait_a){
  out = lapply(trait_levels_verb, function(trait_b){
    ks.test(fst_out_df$Fst[fst_out_df$phenotype == trait_a],
            fst_out_df$Fst[fst_out_df$phenotype == trait_b])
  })
  return(out)
})

# Height v BMI
ks.test(fst_out_df$Fst[fst_out_df$phenotype == "Height"],
        fst_out_df$Fst[fst_out_df$phenotype == "BMI"])

# Height v EA
ks.test(fst_out_df$Fst[fst_out_df$phenotype == "Height"],
        fst_out_df$Fst[fst_out_df$phenotype == "Educational attainment"])

# Height v Intelligence
ks.test(fst_out_df$Fst[fst_out_df$phenotype == "Height"],
        fst_out_df$Fst[fst_out_df$phenotype == "Intelligence"])

# Height v IBD
ks.test(fst_out_df$Fst[fst_out_df$phenotype == "Height"],
        fst_out_df$Fst[fst_out_df$phenotype == "IBD"])

# Height v Pigmentation
ks.test(fst_out_df$Fst[fst_out_df$phenotype == "Height"],
        fst_out_df$Fst[fst_out_df$phenotype == "Pigmentation"])
```


### With just YRI, CEU, and CHS

#### Get Fst stats

```{r}
# get samples from target popns only
target_popns <- which(populations %in% c("YRI", "CEU", "CHS"))
populations_3pop <- populations[target_popns]

vcf_list_raw_3pop <- lapply(vcf_list_raw, function(pheno){
  pheno[target_popns, ]
})

# Generate Fst stats
fst_out_lst_3pop <- lapply(vcf_list_raw_3pop, function(pheno){
  as.data.frame(pegas::Fst(pheno, pop = populations_3pop))
})

# make rownames into separate column
fst_out_lst_3pop <- lapply(fst_out_lst_3pop, function(pheno){
  pheno$snp <- rownames(pheno)
  return(pheno)
})

# bind into single DF
fst_out_df_3pop <- dplyr::bind_rows(fst_out_lst_3pop, .id = "phenotype")

# Recode phenotype
fst_out_df_3pop$phenotype <- factor(fst_out_df_3pop$phenotype, levels = trait_levels)
fst_out_df_3pop$phenotype = dplyr::recode(fst_out_df_3pop$phenotype, !!!recode_vec)

knitr::kable(head(fst_out_df_3pop))

```

#### Plot density

##### 2D

```{r, warning=F}
ggplot(fst_out_df_3pop, aes(Fst, fill = phenotype)) +
  geom_density(alpha = 0.7) +
  labs(fill = "Phenotype") +
  ylab("Density") +
  theme_bw() +
  scale_fill_manual(values = pal_primary)
```

##### 3D

```{r, warning=F, message = F}
ggplot() +
  geom_density_ridges2(data = fst_out_df_3pop,
                       mapping = aes(x = Fst, y = phenotype, fill = phenotype),
                       scale = 2) +
  scale_fill_manual(values = pal_primary) +
  ylab(label = NULL) +
  theme_bw() +
  guides(fill = guide_legend(reverse=T, 
                             title = "Phenotype")) +
  scale_y_discrete(expand = expand_scale(add = c(0.2, 2.3)))
```


#### Run Kolmogorov-Smirnov Tests

```{r, warning = F}
# Height v EA
ks.test(fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "Height"],
        fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "Educational attainment"])

# Height v IBD
ks.test(fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "Height"],
        fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "IBD"])

# Height v Pigmentation
ks.test(fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "Height"],
        fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "Pigmentation"])
```

