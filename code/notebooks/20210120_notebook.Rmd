---
title: "Human traits Fst"
author: "Ian Brettell"
date: "5 January 2021"
#output: html_notebook
#editor_options: 
#  chunk_output_type: inline
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    keep_md: true
    pandoc_args: ["--lua-filter=color-text.lua"]
    highlight: pygments  
---

# Setup

* [Working directory]{color="#4f0943"} on EBI Cluster: `/hps/research1/birney/users/ian/hmn_fst`
* [GitHub repository]{color="#4f0943"}: <https://github.com/brettellebi/human_traits_fst>

## `conda` env on cluster

```{r, engine='bash', eval = F}
# Create env on cluster with mamba
mamba create -y \
  -n fst_env_rhel \
  -c bioconda gatk4
conda activate fst_env_rhel
mamba install bcftools plink2 r-base r-essentials r-tidyverse r-units libgdal r-sf
# Export
conda env export \
  --no-builds \
  -f envs/fst_env_rhel.yml
# Activate
conda activate fst_env_rhel
```

## `renv`

```{r, eval = F}
# Export env (to renv.lock file)
renv::init()
# To install packages on new system, or 'activate' the env: 
renv::restore()
```

## Source libraries, functions and plotting parameters

```{r, warning = F, message = F}
library(here)

source(here::here("code", "scripts", "source.R"))
```

## Download 1GK data

### Download from FTP

```{r, engine='bash', eval = F}
wget \
  -r -p -k \
  --no-parent \
  -cut-dirs=5 \
  ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/
```

### Put filenames into list

```{r, engine='bash', eval = F}
find vcfs/ftp.1000genomes.ebi.ac.uk/ALL.chr*.vcf.gz \
  > human_traits_fst/data/20200205_vcfs.list
```

### Merge VCFs

```{r, engine='bash', eval = F}
java -jar /nfs/software/birney/picard-2.9.0/picard.jar MergeVcfs \
  I=human_traits_fst/data/20200205_vcfs.list \
  O=vcfs/1gk_all.vcf.gz
# Exception in thread "main" java.lang.IllegalArgumentException: The contig entries in input file /hps/research1/birney/users/ian/rac_hyp/vcfs/ftp.1000genomes.ebi.ac.uk/ALL.chrMT.phase3_callmom-v0_4.20130502.genotypes.vcf.gz are not compatible with the others.

# So remove that one from list above
sed -i '/MT/d' human_traits_fst/data/20200205_vcfs.list

# run MergeVCFs again
java -jar /nfs/software/birney/picard-2.9.0/picard.jar MergeVcfs \
  I=human_traits_fst/data/20200205_vcfs.list \
  O=vcfs/1gk_all.vcf.gz
  
# Exception in thread "main" java.lang.IllegalArgumentException: The contig entries in input file /hps/research1/birney/users/ian/rac_hyp/vcfs/ftp.1000genomes.ebi.ac.uk/ALL.chrY.phase3_integrated_v2a.20130502.genotypes.vcf.gz are not compatible with the others.
sed -i '/chrY/d' human_traits_fst/data/20200205_vcfs.list

# run MergeVCFs again
java -jar /nfs/software/birney/picard-2.9.0/picard.jar MergeVcfs \
  I=human_traits_fst/data/20200205_vcfs.list \
  O=vcfs/1gk_all.vcf.gz
# SUCCESS
```

## Obtain GWAS data from the GWAS Catalog <https://www.ebi.ac.uk/gwas>

### Pull data for each trait

[**NOTE**]{colour = "red"}: Uncheck `Include child trait data` before downloading.

All documents downloaded via 'Download Catalog data' link, then collated and saved here: `data/20210122_gwas_catalog.xlsx`

#### Height

* height: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0004339>
  - **4912 SNPs** from **51 studies**
  
#### BMI

* bmi: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0004340>
  - **7573 SNPs** from **155 studies**
  
#### Educational attainment

* self reported educational attainment: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0004784>
  - **3989 SNPs** from **24 studies**
  
#### Intelligence

* intelligence: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0004337>
  - **2967 SNPs** from **27 studies**
  
#### IBD

* inflammatory bowel disease: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0003767>
  - **536 SNPs** from **34 studies**

#### Pigmentation

* skin pigmentation: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0003784>
  - **102 SNPs** from **6 studies**

* skin pigmentation measurement: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0007009>
  - **233 SNPs** from **9 studies**

* eye color: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0003949>
  - **77 SNPs** from **13 studies**
  
* eye colour measurement:
<https://www.ebi.ac.uk/gwas/efotraits/EFO_0009764>
  - **202 SNPs** from **9 studies**
  
* hair color: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0003924>
  - **424 SNPs** from **18 studies**
  
* hair colour measurement: <https://www.ebi.ac.uk/gwas/efotraits/EFO_0007822>
  - **541 SNPs** from **6 studies**

### Read into list

```{r}
file_in = here::here("data", "20210122_gwas_catalog.xlsx")
# Create vector of traits
traits = c("hei", "bmi", "edu", "int", "ibd", "pig")
names(traits) = traits
# Assign sheets to traits
sheets <- seq(1:11)
names(sheets) <- c("hei", "bmi", "edu", "int", "ibd", rep("pig", 6))

# get sheets
sheet_names <- readxl::excel_sheets(file_in)

# Create function to read in data
read_catalog_data <- function(path, target_sheet){
  # Read in data
  out = readxl::read_xlsx(path, sheet = target_sheet) %>% 
    dplyr::select(CHR = CHR_ID, 
                  POS = CHR_POS, 
                  SNP_AL = `STRONGEST SNP-RISK ALLELE`, 
                  P = `P-VALUE`, 
                  OR_OR_BETA = `OR or BETA`, 
                  MAPPED_TRAIT,
                  STUDY = `STUDY ACCESSION`) %>% 
    # Split SNP and risk allele into separate columns
    dplyr::mutate(TOP_SNP = stringr::str_split(SNP_AL, "-", simplify = T)[, 1],
                  RISK_ALLELE = stringr::str_split(SNP_AL, "-", simplify = T)[, 2]) %>% 
    # Reorder and select
    dplyr::select(CHR, POS, TOP_SNP, RISK_ALLELE, P, OR_OR_BETA, MAPPED_TRAIT, STUDY)
  # Change variables to specific types
  out$CHR <- as.integer(out$CHR)
  out$POS <- as.numeric(out$POS)
  out$P <- as.numeric(out$P)
  # return DF
  return(out)
}

# Read in data
counter <- 0
data_list = lapply(traits, function(trait){
  # set counter 
  counter <<- counter + 1
  # set target file
  target_file = file_in
  # get target sheet
  target_sheet = sheets[names(sheets) == trait]
  length(target_sheet)
  # read in pigmentation data from multiple sheets and bind into single DF
  if (length(target_sheet) > 1){
    # loop over each sheet
    df <- lapply(target_sheet, function(sheet){
      out <- read_catalog_data(target_file,
                               target_sheet = sheet)
    })
    # set name of each DF to name of sheet (replacing spaces with underscores)
    names(df) = sheet_names[target_sheet] %>% 
      stringr::str_replace_all(" ", "_")
    # bind DFs into single DF
    df <- dplyr::bind_rows(df, .id = "PIG_PHENO")
  } 
  else {
    # read in other data
    df <- read_catalog_data(target_file,
                            target_sheet = target_sheet)
  }
  # Set PHENO column
  df$PHENO <- factor(trait, levels = trait_levels)
  # Recode PHENO
  df$PHENO = dplyr::recode(df$PHENO, !!!recode_vec)
  # Create list
  out = list()
  # Return DF as "raw"
  out[["raw"]] = df
  
  return(out)
})

# How many SNPs in raw data
lapply(data_list, function(x) nrow(x[["raw"]]))

# Clean data
data_list = lapply(data_list, function(pheno){
  df_clean = pheno[["raw"]]
  # Remove rows with p-value of 0 (only 32 of them, associated with suntan)
  df_clean = df_clean[df_clean$P != 0, ]
  # Remove rows with NA in CHR
  df_clean = df_clean[!is.na(df_clean$CHR), ]
  # Remove duplicates
  ## Find SNPs that are duplicated
  dupes = unique(df_clean$TOP_SNP[duplicated(df_clean$TOP_SNP) | duplicated(df_clean$TOP_SNP, fromLast = T)])
  ## Select only 1 SNP from each set of duplicated SNPs
  dupe_filt = lapply(dupes, function(dupe){
    # Take the one with the lowest P-value
    min_p = min(df_clean$P[df_clean$TOP_SNP == dupe])
    out = df_clean[df_clean$TOP_SNP == dupe & df_clean$P == min_p, ]
    # If there are still duplicates due to having equal P, take the one with the largest effect size
    if (nrow(out) > 1 ){
      out = out[which.max(out$OR_OR_BETA), ]
    }
    return(out)
  })
  # Bind list into DF
  dupe_filt = dplyr::bind_rows(dupe_filt)
  # Extract non-duplicated rows
  non_dupe = df_clean[!duplicated(df_clean$TOP_SNP) & !duplicated(df_clean$TOP_SNP, fromLast = T), ]
  # Bind non-duplicated rows with filtered duplicates
  df_clean = rbind(non_dupe, dupe_filt) 
  # Add to list
  pheno[["clean"]] = df_clean
  
  return(pheno)
})

# New SNP count
lapply(data_list, function(x) nrow(x[["clean"]]))
```

```{r}
lapply(data_list, function(pheno){
  knitr::kable(head(pheno[["clean"]]))
})
```

Get unique mapped traits

```{r}
lapply(data_list, function(pheno){
  unique(pheno$clean$MAPPED_TRAIT)
})
```

### Generate Manhattan plots

Plot

```{r}
# Create function to plot
counter = 0
lapply(data_list, function(pheno_df){
  # set counter
  counter <<- counter + 1
  df = pheno_df[["clean"]]
  trait = unique(df$PHENO)
  # Get title
  title <- paste(trait, "\n", "SNP count:", nrow(df))
  # Plot
  get_man(df, trait = trait, chr = "CHR", bp = "POS", snp = "TOP_SNP", p = "P")
})
```

Save

```{r, eval = F}
output_dir = here::here("plots", "20210122_manhattan_all_snps")

counter = 0
lapply(data_list, function(pheno_df){

  # set counter
  counter <<- counter + 1
  df = pheno_df[["clean"]]
  trait = unique(df$PHENO)
  # Get title
  title <- paste(trait, "\n", "SNP count:", nrow(df))
  # Set file name to save
  file = file.path(output_dir,
                   paste("manhattan_",
                         names(data_list)[counter],
                         ".svg",
                         sep = ""))
  # Set up graphics device
  svg(file,
      width = 10,
      height = 6)  
  
  # Plot
  get_man(df, trait = trait, chr = "CHR", bp = "POS", snp = "TOP_SNP", p = "P")
  
  dev.off()
})
```

#### Create list of target SNPs to extract from 1KG

```{r, eval = F, warning = F, results = "hide"}

dest_dir = here::here("data", "20210122_snp_hit_lists")

# Make directory
dir.create(dest_dir)
  
# Just SNPs for extracting from 1KG
counter <- 0
lapply(data_list, function(pheno){
  df = pheno[["clean"]]
  # Set counter
  counter <<- counter + 1
  # Set file basename
  trait = names(data_list)[counter]
  filename = paste(trait, ".list", sep = "")
  # Write SNPs to file
  readr::write_lines(df$TOP_SNP, file.path(dest_dir, filename))
})

# SNPs and P-values with header for clumping with Plink
counter <- 0
lapply(data_list, function(pheno){
  df = pheno[["clean"]]
  # Set counter
  counter <<- counter + 1
  # Set file basename
  trait = names(data_list)[counter]
  filename = paste(trait, "_with_P.txt", sep = "")
  # Write SNPs to file
  df %>% 
    dplyr::select(SNP = TOP_SNP, P) %>% 
    readr::write_tsv(file.path(dest_dir, filename))
})
```

## Filter 1KG VCF for target SNPs

```{r, engine='bash', eval = F}

traits=$(echo hei bmi edu int ibd pig)
ref=../refs/hs37d5.fa.gz
in_vcf=../vcfs/1gk_all.vcf.gz
snps_dir=data/20210122_snp_hit_lists
out_dir=../vcfs/snp_hits_filtered

mkdir -p $out_dir

for trait in $(echo $traits ); do
  bsub \
    -M 10000 \
    -o ../log/20210122_extract_snps_$trait.out \
    -e ../log/20210122_extract_snps_$trait.err \
    """
    conda activate fst_env_rhel ;
    gatk SelectVariants \
      -R $ref \
      -V $in_vcf \
      --keep-ids $snps_dir/$trait.list \
      -O $out_dir/$trait.vcf.gz 
    """ ;
done
```

## Get allele frequencies of SNP hits with `Plink2`

### Import 1GK metadata (for sample-population key)

Downloded via this page: <http://www.internationalgenome.org/data>
Download link: <http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/working/20130606_sample_info/20130606_sample_info.xlsx>. 

Saved here: `data/20130606_sample_info.xlsx`

```{r, warning=FALSE, results = 'asis'}
samples_file = here::here("data", "20130606_sample_info.xlsx")

meta = readxl::read_xlsx(samples_file,
                         sheet = "Sample Info") %>%
  dplyr::select(Sample, Population, Gender)

knitr::kable(head(meta))
```

### Write population file for Plink2

```{r, eval = F}
sample_popn_key_file = here::here("data", "plink2_sample_popn_key.txt")

write.table(meta[, 1:2],
            sample_popn_key_file,
            quote = F,
            sep = "\t",
            row.names = F,
            col.names = F)
```

### Run `Plink2` for SNP hits

(Take only biallelic SNPs.)

```{r, engine='bash', eval = F}

conda activate fst_env_rhel

# Set variables

traits=$(echo hei bmi edu int ibd pig)
in_vcf_dir=../vcfs/snp_hits_filtered
popn_file=data/plink2_sample_popn_key.txt
out_dir=data/20210122_snp_hits_alfreqs

# Set up directories
mkdir -p $out_dir

for trait in $(echo $traits); do
  mkdir -p $out_dir/$trait; 
done   

# Run Plink2

## Get AF per population
for trait in $(echo $traits); do
  plink2 \
    --vcf $in_vcf_dir/$trait.vcf.gz \
    --freq \
    --max-alleles 2 \
    --snps-only \
    --pheno iid-only $popn_file \
    --loop-cats PHENO1 \
    --out $out_dir/$trait/$trait ;
done

## Get global AF
for trait in $(echo $traits); do
  plink2 \
    --vcf $in_vcf_dir/$trait.vcf.gz \
    --freq \
    --max-alleles 2 \
    --snps-only \
    --out $out_dir/$trait/$trait.all
done

```

## Compare MAF distributions

### Add allele frequency files

```{r}
target_dir = here::here("data", "20210122_snp_hits_alfreqs")

counter <- 0
data_list = lapply(data_list, function(pheno){
  # set counter 
  counter <<- counter + 1
  # get trait name
  trait = names(data_list)[counter]
  # get file path
  target_path = file.path(target_dir, trait, paste(trait, ".all.afreq", sep = ""))
  # read in data
  clean_af = read_afreq(target_path)
  # add to list
  pheno[["clean_af"]] = clean_af
  
  return(pheno)
})
```

<!--
### Convert to MAJ/MIN alleles to get MAF

```{r}
data_list = lapply(data_list, function(pheno){
  df = pheno[["clean_af"]]
  # convert to MAF
  df = df %>% 
    dplyr::mutate(MAJ = if_else(ALT_FREQS <= 0.5,
                                REF,
                                ALT),
                  MIN = ifelse(ALT_FREQS <= 0.5,
                               ALT,
                               REF),
                  MAF = ifelse(ALT_FREQS <= 0.5,
                               ALT_FREQS,
                               1 - ALT_FREQS))
  pheno[["clean_af"]] = df
  
  return(pheno)
})
```

### Histograms of the global MAF distributions (i.e. all 26 populations together)

```{r}
# Extract clean_af DFs
alfreq_list_glob = lapply(data_list, function(pheno) pheno[["clean_af"]])

# Merge into single Df
alfreq_glob_df = dplyr::bind_rows(alfreq_list_glob, .id = "trait")

# Make `trait` a factor
alfreq_glob_df$trait = factor(alfreq_glob_df$trait, levels = trait_levels)
# Recode traits for plotting
alfreq_glob_df$trait = dplyr::recode(alfreq_glob_df$trait, !!!recode_vec)
```

Plot
```{r, fig.height=4, fig.width=6.5}
alfreq_glob_df %>% 
  ggplot(aes(MAF, fill = trait)) +
    geom_histogram(bins = 50) +
    scale_fill_manual(values = pal_primary) +
    facet_wrap(~trait, nrow = 2) +
    guides(fill = F) +
    theme_bw() +
    ggtitle("MAF distributions (all 1KG populations combined)")
```

```{r, eval = F}
# Save
ggsave(here("plots", "20210114_global_maf_distributions.svg"),
       device = "svg",
       units = "cm",
       dpi = 400,
       height = 12,
       width = 19.5)
```

-->

## Set up negative controls

Pull out random SNPs with the same global allele frequencies as the GWAS SNP-hits

### Bin SNP hits by allele frequency

Bind to clean DF to get AFs of risk allele

```{r}
data_list = lapply(data_list, function(pheno){
  # join DFs
  df = dplyr::left_join(pheno[["clean"]],
                        dplyr::select(pheno[["clean_af"]],
                                      -X.CHROM),
                        by = c("TOP_SNP" = "ID"))
  # get AF of risk allele
  df$RISK_AF = dplyr::if_else(df$RISK_ALLELE == df$ALT,
                              df$ALT_FREQS,
                              1 - df$ALT_FREQS)
  # add to list
  pheno[["consol"]] = df
  
  return(pheno)
})
```

Plot RISK_AF against OR_OR_BETA

```{r}
af_plot = lapply(data_list, function(pheno) pheno[["consol"]])
af_plot  = dplyr::bind_rows(af_plot)
```

```{r}
af_plot %>% 
  ggplot() +
    geom_point(aes(RISK_AF, OR_OR_BETA, colour = PHENO)) +
    scale_colour_manual(values = pal_primary) +
    facet_wrap(~PHENO, nrow = 2) +
    guides(colour = F, alpha = F) +
    theme_bw() +
    ggtitle("Risk allele frequency vs effect size (OR or beta)")

# Zoom in
af_plot %>% 
  ggplot() +
    geom_point(aes(RISK_AF, OR_OR_BETA,
                   colour = PHENO,
                   alpha = 0.1)) +
    scale_colour_manual(values = pal_primary) +
    facet_wrap(~PHENO, nrow = 2) +
    guides(colour = F, alpha = F) +
    theme_bw() +
    ggtitle("Risk allele frequency vs effect size (OR or beta)") +
    ylim(0,20)
```
Looks strange.

Bin by risk allele frequency

```{r}
# 1% intervals
breakpoints = seq(0, 1, 0.01)

data_list = lapply(data_list, function(pheno){
  # choose DF
  df = pheno[["consol"]]
  # add bins
  df$BIN_100 = cut(df$RISK_AF, breaks = breakpoints, labels = F)
  # save back into list
  pheno[["consol"]] = df
  
  return(pheno)
})

```

Extract key columns and write to file

```{r, eval = F}
# Save list
risk_afs = lapply(data_list, function(pheno){
  df = pheno[["consol"]]
  # extract key columns
  df = df %>% 
    dplyr::select(TOP_SNP, PHENO, BIN_100)
  
  return(df)
}) %>% 
  # bind into DF and drop NAs
  dplyr::bind_rows() %>% 
  tidyr::drop_na()

readr::write_tsv(risk_afs, here::here("data", "20210121_risk_afs.txt"))
```

### Bin 1KG SNPs 

#### Get allele frequencies from 1KG

With `Plink2`, per chromosome for speed.

```{r, engine='bash', eval=F}
# set output directory
date=20210120
in_file=vcfs/1gk_all.vcf.gz
out_dir=big_data/$date\_alfreqs_all

# Per chromosome
for chr in $(seq 1 22) ; do
  # create allele-freq tables
  bsub \
    -M 10000 \
    -o log/$date\_plink_alfreq_$chr.out \
    -e log/$date\_plink_alfreq_$chr.err \
    """
    conda activate fst_env_rhel ;
    plink2 \
      --vcf $in_file \
      --freq \
      --chr $chr \
      --max-alleles 2 \
      --snps-only \
      --out $out_dir/$chr ";
done 
```

#### Bin them and save to single file

```{r, eval = F}
# On cluster

library(here)
source(here::here("code", "scripts", "source.R"))

# Set variables
in_dir = "../big_data/20210120_alfreqs_all"
out_dir = "../big_data/20210120_alfreqs_all_binned"
breakpoints = seq(0, 1, 0.01) # 1% bins

# Create output directory
dir.create(out_dir)

# Get list of input files
in_files = list.files(in_dir, pattern = ".afreq", full.names = T)

# Read in files, add bins, and write to output
freq_list = lapply(in_files, function(chr_file){
  # read in file
  df = read_afreq(chr_file)
  # add bins
  df$BIN_100 = cut(df$ALT_FREQS, breaks = breakpoints, labels = F)
  # write file
  readr::write_tsv(df, file = file.path(out_dir, basename(chr_file)))
})

# Combine into single DF
freq_df = dplyr::bind_rows(freq_list)

# Write to file
readr::write_tsv(freq_df, file = file.path(out_dir, "all.afreq"))
```

#### Pull out random SNPs with same AF as trait risk alleles

```{r}
# On cluster

library(here)
source(here::here("code", "scripts", "source.R"))

# Variables
target_snp_df = here::here("data", "20210121_risk_afs.txt")
all_1kg_bins = "../big_data/20210120_alfreqs_all_binned/all.afreq"
initial_seed = 123
output_file = here::here("data", "20210121_risk_afs_with_random_snps.txt")
random_snp_list_out = here::here("data", "20210121_random_snps.list")

## Read in target SNP DF and split into list by bin
risk_list = readr::read_tsv(target_snp_df,
                            col_names = T) %>% 
  split(., f = .$BIN_100)

## Read in 1KG data
freq_df = readr::read_tsv(all_1kg_bins)

# For each bin in `risk_list`, pull out the same number of random number 1KG SNPs with the same bin

## Set seed
set.seed(initial_seed)

## Get seeds for each bin
seeds = sample(1:1000, length(risk_list))

## Run over list
counter <- 0
out = lapply(risk_list, function(bin_df){
  # set counter 
  counter <<- counter + 1
  # get target bin
  target_bin = as.integer(names(risk_list)[counter])
  # set seed
  set.seed(seeds[counter])
  # get number of matches required
  hits_n = nrow(bin_df)
  # filter 1kg DF for SNPs with same bin and get random hits
  random_hits = freq_df %>% 
    dplyr::select(SNP, BIN_100) %>% 
    dplyr::filter(BIN_100 == target_bin) %>% 
    dplyr::slice_sample(n = hits_n) %>% 
    dplyr::rename(RANDOM_SNP = SNP,
                  RANDOM_BIN_100 = BIN_100)
  # bind `random_hits` to target SNP df
  df_out = cbind(bin_df, random_hits)
  
  return(df_out)
}) %>% 
  # bind into single data frame
  dplyr::bind_rows()

# Save matches to file
readr::write_tsv(out, output_file)

# Save just SNPs to file (for Plink)
random_snps = out$RANDOM_SNP

readr::write_lines(random_snps, random_snp_list_out)
```

#### Get per-population allele frequencies of random SNPs 

```{bash}

conda activate fst_env_rhel 

date=20210121
random_snps_list=data/20210121_random_snps.list
in_vcf=../vcfs/1gk_all.vcf.gz
popn_key=data/plink2_sample_popn_key.txt
out_dir=data/$date\_random_snps_plink/
mkdir -p $out_dir
out=$out_dir/random

plink2 \
  --vcf $in_vcf \
  --extract $random_snps_list \
  --freq \
  --pheno iid-only $popn_key \
  --loop-cats PHENO1 \
  --out $out
```

#### Bind into single DF and save

```{r}
# On cluster
## conda activate fst_env_rhel

library(here)
source(here::here("code", "scripts", "source.R"))

in_file_random = here::here("data", "20210121_risk_afs_with_random_snps.txt")
in_dir_afreq = here::here("data", "20210121_random_snps_plink")

# Read in data

## Random SNPs
random_snps = readr::read_tsv(in_file_random)

## Popn afreqs
target_files = list.files(in_dir_afreq, pattern = ".afreq", full.names = T)

names(target_files) = basename(target_files) %>% 
  str_split("\\.", simplify = T) %>% 
  subset(select = 2)

popn_afreqs = lapply(target_files, function(popn){
  df = read_afreq(popn)
}) %>% 
  dplyr::bind_rows(.id = "POPN") %>% 
  dplyr::select(-OBS_CT) %>% 
  tidyr::pivot_wider(id_cols = SNP, names_from = POPN, values_from = ALT_FREQS)
```

## Clump to get lead SNPs

Use `Plink1.9` (`Plink2.0` doesn't have a `clump` function.)

From the `Plink1.7` documentation (<http://zzz.bwh.harvard.edu/plink/clump.shtml>), which applies to `Plink1.9`:

> The clumping procedure takes all SNPs that are significant at threshold p1 that have not already been clumped (denoting these as index SNPs) and forms clumps of all other SNPs that are within a certain kb distance from the index SNP (default 250kb) and that are in linkage disequilibrium with the index SNP, based on an r-squared threshold (default 0.50)... This is a greedy algorithm and so each SNP will only appear in a single clump, if at all. 

> ...[t]he TOTAL field lists all SNPs that are clumped with the index SNP, irrespective of the p-value for those SNPs. This number is then split into those clumped SNPs that are not significant (p>0.05) and various other groups defined by significance thresholds. For SNPs that are significant at the p2 threshold, they are listed explicitly. The (1) after each SNP name refers to the results file they came from (in this case, there is only a single result file specified, so all values are 1).

Here, we're taking all SNPs with *P* < 1e-08 as index SNPs, and it will explicitly list all SNPs within the clump that also meet that threshold. 

```{bash}

# Activate environment
conda activate fst_env_rhel

# Set variables
date=20210122
traits=$(echo hei bmi edu int ibd pig)
in_vcf=../vcfs/1gk_all.vcf.gz
snp_p_pref=data/20210120_snps
out_dir=data/$date\_clumped

r2_params=$(echo 0.7 0.8 0.9)
kb_params=$(echo 500 750 1000 )

# Make directory
mkdir -p $out_dir

# Run with different parameters
for trait in $(echo $traits ); do
  for r2 in $r2_params ; do
    for kb in $kb_params ; do
      bsub \
        -o ../log/$date\_clump_$trait\_$r2\_$kb.out \
        -e ../log/$date\_clump_$trait\_$r2\_$kb.err \
        """
        conda activate fst_env_rhel ;
        plink \
          --vcf $in_vcf \
          --clump $snp_p_pref\_$trait\_with_P.txt \
          --clump-p1 0.00000001 \
          --clump-p2 0.00000001 \
          --clump-r2 $r2 \
          --clump-kb $kb \
          --out $out_dir/$trait\_r2-$r2\_kb-$kb 
        """  ;
    done ;
  done;  
done

```

### Add clumped SNP files

```{r}
target_dir = here::here("data", "20210120_clumped")

counter <- 0
data_list = lapply(data_list, function(pheno){
  # set counter 
  counter <<- counter + 1
  # get trait name
  trait = names(data_list)[counter]
  # get file path
  target_path = file.path(target_dir, paste(trait, ".clumped", sep = ""))
  # read in data
  clumped_df = read.table(target_path,header = T)
  # add to list
  pheno[["clumped"]]  = clumped_df
  
  return(pheno)
})
```

## Compare allele frequencies

### Read in data

```{r}
target_dirs <- list.dirs(here::here("data", "20200622_plink2_alfreqs"), recursive = F)

al_freq_lst <- lapply(target_dirs, function(x){
  target_files <- list.files(x, pattern = ".afreq", full.names = T)
  # read in data
  data_lst <- lapply(target_files, function(target_file){
    read.table(target_file,
               header = T,
               comment.char = "")
  })
  # fix names of populations
  names(data_lst) <- gsub(pattern = "edu.|hei.|bmi.|ibd.|pig.|.afreq",
                          replacement = "",
                          x = list.files(x, pattern = ".afreq"))
  return(data_lst)
})

# set names
names(al_freq_lst) <- basename(target_dirs)

# reorder for (1) height, (2) eduyears, (3) ibd, (4) pigmentation
al_freq_lst <- al_freq_lst[c(2, 1, 3, 4)]
```

### Turn into single table for each pheno

```{r}
al_freq_df <- lapply(al_freq_lst, function(pheno){
  out <- dplyr::bind_rows(pheno, .id = "population") %>% 
    tidyr::pivot_wider(id_cols = c(X.CHROM, ID, REF, ALT),
                       names_from = population,
                       values_from = ALT_FREQS)
})
```

### Randomly swap minor allele

```{r}
set.seed(65)
rdm_sds <- sample(1:100, 4)

counter <- 0
al_freq_df_shuff <- lapply(al_freq_df, function(pheno){
  counter <<- counter + 1
  # set seed
  set.seed(rdm_sds[counter])
  # select SNPs to swap (half of total)
  tgt_indcs <- sample(nrow(pheno), nrow(pheno) /2)
  # swap minor alleles
  pheno[tgt_indcs, 5:ncol(pheno)] <- 1 - pheno[tgt_indcs, 5:ncol(pheno)]
  # return pheno
  return(pheno)
})
```

# Analysis



### Read in population frequency data

```{r}
target_dirs <- list.dirs(here::here("data", "20200622_plink2_alfreqs"), recursive = F)

al_freq_lst <- lapply(target_dirs, function(x){
  target_files <- list.files(x, pattern = ".afreq", full.names = T)
  # read in data
  data_lst <- lapply(target_files, function(target_file){
    read.table(target_file,
               header = T,
               comment.char = "")
  })
  # fix names of populations
  names(data_lst) <- gsub(pattern = "edu.|hei.|bmi.|ibd.|pig.|.afreq",
                          replacement = "",
                          x = list.files(x, pattern = ".afreq"))
  return(data_lst)
})

# set names
names(al_freq_lst) <- basename(target_dirs)
```

### Turn into single table for each pheno

```{r}
al_freq_df <- lapply(al_freq_lst, function(pheno){
  out <- dplyr::bind_rows(pheno, .id = "population") %>% 
    tidyr::pivot_wider(id_cols = c(X.CHROM, ID, REF, ALT),
                       names_from = population,
                       values_from = ALT_FREQS)
})
```

### Randomly swap minor allele

```{r}
set.seed(65)
rdm_sds <- sample(1:100, 5)

counter <- 0
al_freq_df_shuff <- lapply(al_freq_df, function(pheno_df){
  counter <<- counter + 1
  # set seed
  set.seed(rdm_sds[counter])
  # select SNPs to swap (half of total)
  tgt_indcs <- sample(nrow(pheno_df), nrow(pheno_df) /2)
  # swap minor alleles
  pheno_df[tgt_indcs, 5:ncol(pheno_df)] <- 1 - pheno_df[tgt_indcs, 5:ncol(pheno_df)]
  # return pheno_df
  return(pheno_df)
})
```

### Bind in to single data frame and save

```{r}
final = dplyr::bind_rows(al_freq_df_shuff, .id = "phenotype")
```

```{r, eval = F}
final %>% 
  readr::write_tsv(here("data", "20210114_pheno_alfreqs.txt.gz"))
```


### Plot

```{r}
# Set up titles vector
titles <- c("Height", "Educational Attainment", "Inflammatory Bowel Disease", "Pigmentation")
```

#### 2D

##### YRI v CHS

```{r, message=F, warning=F}
counter <- 0
lapply(al_freq_df_shuff, function(pheno){
  counter <<- counter + 1
  ggplot(pheno,
         aes(YRI, CHS)) +
    geom_point(size = 0.5) +
    coord_fixed() +
    geom_smooth(se = F, colour = "red") +
    geom_abline(intercept = 0, slope = 1, colour = "blue") +
    xlab("Allele frequency in YRI") +
    ylab("Allele frequency in CHS") +
    labs(title = titles[counter])
})
```

##### YRI v CEU

```{r, message=F, warning=F}
counter <- 0
lapply(al_freq_df_shuff, function(pheno){
  counter <<- counter + 1
  ggplot(pheno,
         aes(YRI, CEU)) +
    geom_point(size = 0.5) +
    coord_fixed() +
    geom_smooth(se = F, colour = "red") +
    geom_abline(intercept = 0, slope = 1, colour = "blue") +
    xlab("Allele frequency in YRI") +
    ylab("Allele frequency in CEU") +
    labs(title = titles[counter])
})
```

#### 3D

```{r, message=F, warning=F}
colourscales <- c("Viridis", "Hot", "Bluered", "Electric")
titles <- c("Height", "Educational Attainment", "IBD", "Skin/hair pigmentation")

counter <- 0
plts <- lapply(al_freq_df_shuff, function(pheno){
  counter <<- counter + 1
  # set graph resolution
  graph_reso <- 0.05
  # get lm for data
  loess_model <- loess(CEU ~ 0 + CHS + YRI, data = pheno)
  # set up axes
  axis_x <- seq(min(pheno$CHS), max(pheno$CHS), by = graph_reso)
  axis_y <- seq(min(pheno$YRI), max(pheno$YRI), by = graph_reso)
  # sample points
  lm_surface <- expand.grid(CHS = axis_x,
                            YRI = axis_y,
                            KEEP.OUT.ATTRS = F)
  lm_surface$CEU <- predict(loess_model, newdata = lm_surface)
  lm_surface <- reshape2::acast(lm_surface, YRI ~ CHS, value.var = "CEU")
  # create plot
  plt <- plot_ly(pheno,
                 x = ~CHS,
                 y = ~YRI,
                 z = ~CEU,
                 type = "scatter3d",
                 mode = "markers",
                 marker = list(size = 2),
                 text = pheno$ID) 
  plt <- add_trace(plt,
                   z = lm_surface,
              x = axis_x,
              y = axis_y,
              type = "surface",
              colorscale = colourscales[counter]) %>% 
    layout(title = titles[counter])
  return(plt)
})

plts$hei
plts$edu
plts$ibd
plts$pig
```

## Fst

### Find target VCFs

```{r}
# list target VCFs
target_vcfs <- list.files(here::here("data"),
                          pattern = glob2rx("snphits_*.gz"), 
                          full.names = T)

# filter for the four we want
target_vcfs <- target_vcfs[grep("eduyrs|height|ibd_full|pig", target_vcfs)]


```

### With all populations

#### Get Fst stats

```{r, message=F, warning=F, results=F}
# Create raw list of variants
vcf_list_raw <- lapply(target_vcfs, function(vcf_file){
  vcf_out <- pegas::read.vcf(vcf_file)
})

# Create vector of populations
populations <- unlist(lapply(rownames(vcf_list_raw[[1]]), function(sample){
  meta$Population[meta$Sample == sample]
}))

# Generate Fst stats
fst_out_lst <- lapply(vcf_list_raw, function(pheno){
  as.data.frame(pegas::Fst(pheno, pop = populations))
})

# make rownames into separate column
fst_out_lst <- lapply(fst_out_lst, function(pheno){
  pheno$snp <- rownames(pheno)
  return(pheno)
})
names(fst_out_lst) <- titles

# bind into single DF
fst_out_df <- dplyr::bind_rows(fst_out_lst, .id = "phenotype")

# Set order of phenotypes
fst_out_df$phenotype <- factor(fst_out_df$phenotype, levels = c("Height", "Educational Attainment", "IBD", "Skin/hair pigmentation"))

head(fst_out_df)
```

#### Plot density

##### 2D

```{r, warning= F}
ggplot(fst_out_df, aes(Fst, fill = phenotype)) +
  geom_density(alpha = 0.7) +
  labs(fill = "Phenotype") +
  ylab("Density") +
  theme_bw() +
  scale_fill_manual(values = c("#E7B800", "#00AFBB", "#360568", "#FC4E07"))
```

##### 3D

```{r, warning = F, message = F}
# factorise 
fst_out_df$phenotype_3d <- factor(fst_out_df$phenotype,
                                    levels = c("Skin/hair pigmentation", "IBD", "Educational Attainment", "Height"))

ggplot() +
  geom_density_ridges2(data = fst_out_df,
                       mapping = aes(x = Fst, y = phenotype_3d, fill = phenotype_3d),
                       scale = 2) +
  scale_fill_manual(values = c("#FC4E07", "#360568", "#00AFBB", "#E7B800")) +
  ylab(label = NULL) +
  theme_bw() +
  guides(fill = guide_legend(reverse=T, 
                             title = "Phenotype")) +
  scale_y_discrete(expand = expand_scale(add = c(0.2, 2.3)))
```

#### Run Kolmogorov-Smirnov Tests

```{r, warning = F}
# Height v EA
ks.test(fst_out_df$Fst[fst_out_df$phenotype == "Height"],
        fst_out_df$Fst[fst_out_df$phenotype == "Educational Attainment"])

# Height v IBD
ks.test(fst_out_df$Fst[fst_out_df$phenotype == "Height"],
        fst_out_df$Fst[fst_out_df$phenotype == "IBD"])

# Height v Pigmentation
ks.test(fst_out_df$Fst[fst_out_df$phenotype == "Height"],
        fst_out_df$Fst[fst_out_df$phenotype == "Skin/hair pigmentation"])
```


### With just YRI, CEU, and CHS

#### Get Fst stats

```{r}
# get samples from target popns only
target_popns <- which(populations %in% c("YRI", "CEU", "CHS"))
populations_3pop <- populations[target_popns]

vcf_list_raw_3pop <- lapply(vcf_list_raw, function(pheno){
  pheno[target_popns, ]
})

# Generate Fst stats
fst_out_lst_3pop <- lapply(vcf_list_raw_3pop, function(pheno){
  as.data.frame(pegas::Fst(pheno, pop = populations_3pop))
})

# make rownames into separate column
fst_out_lst_3pop <- lapply(fst_out_lst_3pop, function(pheno){
  pheno$snp <- rownames(pheno)
  return(pheno)
})
names(fst_out_lst_3pop) <- titles

# bind into single DF
fst_out_df_3pop <- dplyr::bind_rows(fst_out_lst_3pop, .id = "phenotype")
head(fst_out_df_3pop)
```

#### Plot density

##### 2D

```{r, warning=F}
ggplot(fst_out_df_3pop, aes(Fst, fill = phenotype)) +
  geom_density(alpha = 0.7) +
  labs(fill = "Phenotype") +
  ylab("Density") +
  theme_bw() +
  scale_fill_manual(values = c("#E7B800", "#00AFBB", "#360568", "#FC4E07"))
```

##### 3D

```{r, warning=F, message = F}
# factorise 
fst_out_df_3pop$phenotype_3d <- factor(fst_out_df$phenotype,
                                    levels = c("Skin/hair pigmentation", "IBD", "Educational Attainment", "Height"))

ggplot() +
  geom_density_ridges2(data = fst_out_df_3pop,
                       mapping = aes(x = Fst, y = phenotype_3d, fill = phenotype_3d),
                       scale = 2) +
  scale_fill_manual(values = c("#FC4E07", "#360568", "#00AFBB", "#E7B800")) +
  ylab(label = NULL) +
  theme_bw() +
  guides(fill = guide_legend(reverse=T, 
                             title = "Phenotype")) +
  scale_y_discrete(expand = expand_scale(add = c(0.2, 2.3)))
```


#### Run Kolmogorov-Smirnov Tests

```{r, warning = F}
# Height v EA
ks.test(fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "Height"],
        fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "Educational Attainment"])

# Height v IBD
ks.test(fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "Height"],
        fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "IBD"])

# Height v Pigmentation
ks.test(fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "Height"],
        fst_out_df_3pop$Fst[fst_out_df_3pop$phenotype == "Skin/hair pigmentation"])
```

